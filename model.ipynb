{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    batch_size = 50 # b\n",
    "    sequence_l = 128 # n\n",
    "    d_model = 768 # d_modelï¼Œ embedding dim\n",
    "    num_layer = 12 # number of block stacked\n",
    "    number_head = 8 # multihead attention\n",
    "    d_ff = 2048 # feedforward dimension\n",
    "\n",
    "config_model = Config()\n",
    "\n",
    "def read_data(): \n",
    "    text = open('data.txt', 'r').read()\n",
    "    return re.sub('[^A-Za-z:]+',' ',text).strip().lower()\n",
    "\n",
    "data = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters.\n",
    "\n",
    "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, data):\n",
    "        chars = sorted(list(set(data)))  # get characters from the input data\n",
    "        self.stoi = {ch: i for i, ch in enumerate(chars)}  # map characters to integer indices\n",
    "        self.itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "        self.block_size = config.sequence_l\n",
    "        self.data = data\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.stoi)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        idx_chunk = [self.stoi[c] for c in chunk]\n",
    "        x = torch.tensor(idx_chunk[:-1], dtype=torch.long)\n",
    "        # return the chunk and the shifted version as tensors\n",
    "        y = torch.tensor(idx_chunk[1:], dtype=torch.long)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "char_dataset = CharDataset(config_model, data)\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(char_dataset, batch_size=config_model.batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just take first batch for testing embedding\n",
    "for ind,(x,y) in enumerate(data_loader):\n",
    "    if ind != 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        # pe: [seq_lens * 1 * d_model] for each sample\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(config_model):\n",
    "    mask = torch.full([config_model.sequence_l, config_model.sequence_l] , float('-inf'))\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(DecoderBlock, self).__init__()   \n",
    "        self.self_attention =  MultiHeadAttention(d_model,num_heads)\n",
    "        self.norm1 = LayerNormalization()\n",
    "        self.ffn \n",
    "        self.norm2 = LayerNormalization()\n",
    "\n",
    "\n",
    "    def forward(self,x,y,mask):\n",
    "        _x = x # used for skip connection\n",
    "        x = self.self_attention(x,mask) \n",
    "        x = self.norm1(x+_x)\n",
    "\n",
    "        _x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.norm2(x+_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialDecoder(nn.Sequential): # just un intermediate function for calling\n",
    "    def forward(self, x,y,mask):\n",
    "        for module in self._modules.values():\n",
    "            y = module(x,y,mask)\n",
    "            return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask =  create_causal_mask(config_model) #[sequence_l * sequence_l]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, src_vovab_size, ffn_hidden, num_heads, drop_prob, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tok_emb = nn.Embedding(src_vovab_size,d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.dropout1 = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.layers = SequentialDecoder(*[DecoderBlock(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, x,y,mask):\n",
    "\n",
    "        emb_x = self.tok_emb(x)\n",
    "        emb_x = self.pos_emb(emb_x) # x,y = emb = [batch size * sequence_l * d_model]\n",
    "        emb_x = self.dropout1(emb_x)\n",
    "\n",
    "        y = self.layers(emb_x,y,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecoderLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yy\\Desktop\\dl_project\\model.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m src_vovab_size \u001b[39m=\u001b[39m char_dataset\u001b[39m.\u001b[39mget_vocab_size()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dec \u001b[39m=\u001b[39m Decoder(config_model\u001b[39m.\u001b[39;49md_model,src_vovab_size,config_model\u001b[39m.\u001b[39;49md_ff,config_model\u001b[39m.\u001b[39;49mnumber_head,\u001b[39m0.5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m output \u001b[39m=\u001b[39m dec(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;32mc:\\Users\\yy\\Desktop\\dl_project\\model.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtok_emb \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(src_vovab_size,d_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_emb \u001b[39m=\u001b[39m PositionalEncoding(d_model)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m SequentialDecoder(\u001b[39m*\u001b[39m[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_layers)])\n",
      "\u001b[1;32mc:\\Users\\yy\\Desktop\\dl_project\\model.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtok_emb \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(src_vovab_size,d_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_emb \u001b[39m=\u001b[39m PositionalEncoding(d_model)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yy/Desktop/dl_project/model.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m SequentialDecoder(\u001b[39m*\u001b[39m[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_layers)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecoderLayer' is not defined"
     ]
    }
   ],
   "source": [
    "src_vovab_size = char_dataset.get_vocab_size()\n",
    "\n",
    "dec = Decoder(config_model.d_model,src_vovab_size,config_model.d_ff,config_model.number_head,0.5)\n",
    "output = dec(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module): \n",
    "    \"\"\"Scaled dot product attention.\"\"\"\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
