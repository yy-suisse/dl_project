{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import util\n",
    "import custum_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from model import Model\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "path = f'C:/Users/yy/Desktop/dl_project/data/data.txt'  \n",
    "\n",
    "c = util.config()\n",
    "\n",
    "data_train,stoi,itos = util.load_data_with_split(path,c.split,type='train')\n",
    "data_test,_,_ = util.load_data_with_split(path,c.split,type='test')\n",
    "\n",
    "\n",
    "dataset_train = custum_dataset.CustomDataset(c.sequence_l,device,stoi,itos,data_train,repeat = False)\n",
    "data_loader_train = DataLoader(dataset_train, c.batch_size, shuffle=False)\n",
    "\n",
    "dataset_test = custum_dataset.CustomDataset(c.sequence_l,device,stoi,itos,data_test,repeat = False)\n",
    "data_loader_test = DataLoader(dataset_test, c.batch_size, shuffle=False)\n",
    "\n",
    "model = Model(stoi=dataset_train.stoi)\n",
    "m = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=c.learning_rate)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,mode='min', factor=0.1, patience=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "lr decay: https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000, Loss: 4.4066, Perplexity: 81.9923\n",
      "Validation Loss: 4.1352, Validation Perplexity: 62.5041\n",
      "Epoch 2/3000, Loss: 4.0981, Perplexity: 60.2238\n",
      "Validation Loss: 4.0308, Validation Perplexity: 56.3079\n",
      "Epoch 3/3000, Loss: 4.0183, Perplexity: 55.6070\n",
      "Validation Loss: 4.2174, Validation Perplexity: 67.8594\n",
      "Epoch 4/3000, Loss: 4.2068, Perplexity: 67.1440\n",
      "Validation Loss: 4.0780, Validation Perplexity: 59.0274\n",
      "Epoch 5/3000, Loss: 4.0793, Perplexity: 59.1063\n",
      "Validation Loss: 3.8502, Validation Perplexity: 47.0012\n",
      "Epoch 6/3000, Loss: 3.8587, Perplexity: 47.4038\n",
      "Validation Loss: 3.6309, Validation Perplexity: 37.7474\n",
      "Epoch 7/3000, Loss: 3.6469, Perplexity: 38.3571\n",
      "Validation Loss: 3.3972, Validation Perplexity: 29.8809\n",
      "Epoch 8/3000, Loss: 3.4206, Perplexity: 30.5889\n",
      "Validation Loss: 3.1864, Validation Perplexity: 24.2023\n",
      "Epoch 9/3000, Loss: 3.2167, Perplexity: 24.9459\n",
      "Validation Loss: 3.0210, Validation Perplexity: 20.5122\n",
      "Epoch 10/3000, Loss: 3.0574, Perplexity: 21.2730\n",
      "Validation Loss: 2.8242, Validation Perplexity: 16.8467\n",
      "Epoch 11/3000, Loss: 2.8688, Perplexity: 17.6159\n",
      "Validation Loss: 2.6845, Validation Perplexity: 14.6505\n",
      "Epoch 12/3000, Loss: 2.7333, Perplexity: 15.3840\n",
      "Validation Loss: 2.7497, Validation Perplexity: 15.6385\n",
      "Epoch 13/3000, Loss: 2.7923, Perplexity: 16.3182\n",
      "Validation Loss: 2.7019, Validation Perplexity: 14.9080\n",
      "Epoch 14/3000, Loss: 2.7523, Perplexity: 15.6790\n",
      "Validation Loss: 2.5130, Validation Perplexity: 12.3416\n",
      "Epoch 15/3000, Loss: 2.5709, Perplexity: 13.0773\n",
      "Validation Loss: 2.3846, Validation Perplexity: 10.8549\n",
      "Epoch 16/3000, Loss: 2.4329, Perplexity: 11.3919\n",
      "Validation Loss: 2.3195, Validation Perplexity: 10.1709\n",
      "Epoch 17/3000, Loss: 2.3517, Perplexity: 10.5036\n",
      "Validation Loss: 2.2594, Validation Perplexity: 9.5774\n",
      "Epoch 18/3000, Loss: 2.2790, Perplexity: 9.7665\n",
      "Validation Loss: 2.1636, Validation Perplexity: 8.7020\n",
      "Epoch 19/3000, Loss: 2.1735, Perplexity: 8.7886\n",
      "Validation Loss: 2.0529, Validation Perplexity: 7.7905\n",
      "Epoch 20/3000, Loss: 2.0578, Perplexity: 7.8284\n",
      "Validation Loss: 1.9582, Validation Perplexity: 7.0868\n",
      "Epoch 21/3000, Loss: 1.9655, Perplexity: 7.1388\n",
      "Validation Loss: 1.8833, Validation Perplexity: 6.5753\n",
      "Epoch 22/3000, Loss: 1.8966, Perplexity: 6.6632\n",
      "Validation Loss: 1.8222, Validation Perplexity: 6.1852\n",
      "Epoch 23/3000, Loss: 1.8432, Perplexity: 6.3166\n",
      "Validation Loss: 1.7797, Validation Perplexity: 5.9279\n",
      "Epoch 24/3000, Loss: 1.8003, Perplexity: 6.0513\n",
      "Validation Loss: 1.7389, Validation Perplexity: 5.6909\n",
      "Epoch 25/3000, Loss: 1.7570, Perplexity: 5.7948\n",
      "Validation Loss: 1.7112, Validation Perplexity: 5.5356\n",
      "Epoch 26/3000, Loss: 1.7205, Perplexity: 5.5872\n",
      "Validation Loss: 1.6735, Validation Perplexity: 5.3306\n",
      "Epoch 27/3000, Loss: 1.6794, Perplexity: 5.3626\n",
      "Validation Loss: 1.6271, Validation Perplexity: 5.0891\n",
      "Epoch 28/3000, Loss: 1.6361, Perplexity: 5.1352\n",
      "Validation Loss: 1.6069, Validation Perplexity: 4.9873\n",
      "Epoch 29/3000, Loss: 1.6159, Perplexity: 5.0323\n",
      "Validation Loss: 1.5872, Validation Perplexity: 4.8901\n",
      "Epoch 30/3000, Loss: 1.5970, Perplexity: 4.9381\n",
      "Validation Loss: 1.5516, Validation Perplexity: 4.7191\n",
      "Epoch 31/3000, Loss: 1.5620, Perplexity: 4.7682\n",
      "Validation Loss: 1.5160, Validation Perplexity: 4.5541\n",
      "Epoch 32/3000, Loss: 1.5287, Perplexity: 4.6124\n",
      "Validation Loss: 1.4884, Validation Perplexity: 4.4298\n",
      "Epoch 33/3000, Loss: 1.5072, Perplexity: 4.5139\n",
      "Validation Loss: 1.4693, Validation Perplexity: 4.3464\n",
      "Epoch 34/3000, Loss: 1.4896, Perplexity: 4.4355\n",
      "Validation Loss: 1.4553, Validation Perplexity: 4.2858\n",
      "Epoch 35/3000, Loss: 1.4771, Perplexity: 4.3801\n",
      "Validation Loss: 1.4323, Validation Perplexity: 4.1882\n",
      "Epoch 36/3000, Loss: 1.4568, Perplexity: 4.2922\n",
      "Validation Loss: 1.4126, Validation Perplexity: 4.1068\n",
      "Epoch 37/3000, Loss: 1.4343, Perplexity: 4.1967\n",
      "Validation Loss: 1.3973, Validation Perplexity: 4.0442\n",
      "Epoch 38/3000, Loss: 1.4163, Perplexity: 4.1218\n",
      "Validation Loss: 1.3779, Validation Perplexity: 3.9667\n",
      "Epoch 39/3000, Loss: 1.3957, Perplexity: 4.0377\n",
      "Validation Loss: 1.3577, Validation Perplexity: 3.8871\n",
      "Epoch 40/3000, Loss: 1.3831, Perplexity: 3.9872\n",
      "Validation Loss: 1.3447, Validation Perplexity: 3.8371\n",
      "Epoch 41/3000, Loss: 1.3675, Perplexity: 3.9255\n",
      "Validation Loss: 1.3157, Validation Perplexity: 3.7273\n",
      "Epoch 42/3000, Loss: 1.3420, Perplexity: 3.8267\n",
      "Validation Loss: 1.2909, Validation Perplexity: 3.6361\n",
      "Epoch 43/3000, Loss: 1.3185, Perplexity: 3.7377\n",
      "Validation Loss: 1.2725, Validation Perplexity: 3.5696\n",
      "Epoch 44/3000, Loss: 1.3013, Perplexity: 3.6739\n",
      "Validation Loss: 1.2597, Validation Perplexity: 3.5242\n",
      "Epoch 45/3000, Loss: 1.2888, Perplexity: 3.6283\n",
      "Validation Loss: 1.2582, Validation Perplexity: 3.5191\n",
      "Epoch 46/3000, Loss: 1.2805, Perplexity: 3.5984\n",
      "Validation Loss: 1.2268, Validation Perplexity: 3.4104\n",
      "Epoch 47/3000, Loss: 1.2545, Perplexity: 3.5059\n",
      "Validation Loss: 1.1836, Validation Perplexity: 3.2660\n",
      "Epoch 48/3000, Loss: 1.2154, Perplexity: 3.3716\n",
      "Validation Loss: 1.1544, Validation Perplexity: 3.1722\n",
      "Epoch 49/3000, Loss: 1.1892, Perplexity: 3.2846\n",
      "Validation Loss: 1.1426, Validation Perplexity: 3.1349\n",
      "Epoch 50/3000, Loss: 1.1739, Perplexity: 3.2347\n",
      "Validation Loss: 1.1018, Validation Perplexity: 3.0096\n",
      "Epoch 51/3000, Loss: 1.1401, Perplexity: 3.1270\n",
      "Validation Loss: 1.0647, Validation Perplexity: 2.8999\n",
      "Epoch 52/3000, Loss: 1.1044, Perplexity: 3.0175\n",
      "Validation Loss: 1.0375, Validation Perplexity: 2.8222\n",
      "Epoch 53/3000, Loss: 1.0761, Perplexity: 2.9331\n",
      "Validation Loss: 1.0187, Validation Perplexity: 2.7695\n",
      "Epoch 54/3000, Loss: 1.0529, Perplexity: 2.8659\n",
      "Validation Loss: 0.9772, Validation Perplexity: 2.6571\n",
      "Epoch 55/3000, Loss: 1.0160, Perplexity: 2.7622\n",
      "Validation Loss: 0.9479, Validation Perplexity: 2.5802\n",
      "Epoch 56/3000, Loss: 0.9853, Perplexity: 2.6785\n",
      "Validation Loss: 0.8947, Validation Perplexity: 2.4465\n",
      "Epoch 57/3000, Loss: 0.9412, Perplexity: 2.5630\n",
      "Validation Loss: 0.8696, Validation Perplexity: 2.3860\n",
      "Epoch 58/3000, Loss: 0.8973, Perplexity: 2.4529\n",
      "Validation Loss: 0.8146, Validation Perplexity: 2.2583\n",
      "Epoch 59/3000, Loss: 0.8617, Perplexity: 2.3672\n",
      "Validation Loss: 0.7646, Validation Perplexity: 2.1480\n",
      "Epoch 60/3000, Loss: 0.8187, Perplexity: 2.2675\n",
      "Validation Loss: 0.7630, Validation Perplexity: 2.1446\n",
      "Epoch 61/3000, Loss: 0.7823, Perplexity: 2.1865\n",
      "Validation Loss: 0.6851, Validation Perplexity: 1.9839\n",
      "Epoch 62/3000, Loss: 0.7347, Perplexity: 2.0849\n",
      "Validation Loss: 0.6961, Validation Perplexity: 2.0060\n",
      "Epoch 63/3000, Loss: 0.7372, Perplexity: 2.0901\n",
      "Validation Loss: 0.6326, Validation Perplexity: 1.8825\n",
      "Epoch 64/3000, Loss: 0.6700, Perplexity: 1.9542\n",
      "Validation Loss: 0.6350, Validation Perplexity: 1.8869\n",
      "Epoch 65/3000, Loss: 0.6625, Perplexity: 1.9397\n",
      "Validation Loss: 0.5516, Validation Perplexity: 1.7360\n",
      "Epoch 66/3000, Loss: 0.5883, Perplexity: 1.8009\n",
      "Validation Loss: 0.5302, Validation Perplexity: 1.6992\n",
      "Epoch 67/3000, Loss: 0.5713, Perplexity: 1.7705\n",
      "Validation Loss: 0.4828, Validation Perplexity: 1.6206\n",
      "Epoch 68/3000, Loss: 0.5178, Perplexity: 1.6784\n",
      "Validation Loss: 0.4774, Validation Perplexity: 1.6118\n",
      "Epoch 69/3000, Loss: 0.5061, Perplexity: 1.6588\n",
      "Validation Loss: 0.4444, Validation Perplexity: 1.5596\n",
      "Epoch 70/3000, Loss: 0.4766, Perplexity: 1.6106\n",
      "Validation Loss: 0.4277, Validation Perplexity: 1.5337\n",
      "Epoch 71/3000, Loss: 0.4701, Perplexity: 1.6001\n",
      "Validation Loss: 0.4092, Validation Perplexity: 1.5056\n",
      "Epoch 72/3000, Loss: 0.4385, Perplexity: 1.5504\n",
      "Validation Loss: 0.3615, Validation Perplexity: 1.4355\n",
      "Epoch 73/3000, Loss: 0.3939, Perplexity: 1.4827\n",
      "Validation Loss: 0.3470, Validation Perplexity: 1.4149\n",
      "Epoch 74/3000, Loss: 0.3786, Perplexity: 1.4603\n",
      "Validation Loss: 0.3271, Validation Perplexity: 1.3869\n",
      "Epoch 75/3000, Loss: 0.3554, Perplexity: 1.4267\n",
      "Validation Loss: 0.3070, Validation Perplexity: 1.3594\n",
      "Epoch 76/3000, Loss: 0.3330, Perplexity: 1.3951\n",
      "Validation Loss: 0.2800, Validation Perplexity: 1.3231\n",
      "Epoch 77/3000, Loss: 0.3127, Perplexity: 1.3671\n",
      "Validation Loss: 0.2699, Validation Perplexity: 1.3098\n",
      "Epoch 78/3000, Loss: 0.2984, Perplexity: 1.3478\n",
      "Validation Loss: 0.2524, Validation Perplexity: 1.2872\n",
      "Epoch 79/3000, Loss: 0.2774, Perplexity: 1.3197\n",
      "Validation Loss: 0.2348, Validation Perplexity: 1.2646\n",
      "Epoch 80/3000, Loss: 0.2591, Perplexity: 1.2957\n",
      "Validation Loss: 0.2224, Validation Perplexity: 1.2490\n",
      "Epoch 81/3000, Loss: 0.2462, Perplexity: 1.2791\n",
      "Validation Loss: 0.2054, Validation Perplexity: 1.2280\n",
      "Epoch 82/3000, Loss: 0.2336, Perplexity: 1.2631\n",
      "Validation Loss: 0.1994, Validation Perplexity: 1.2207\n",
      "Epoch 83/3000, Loss: 0.2218, Perplexity: 1.2483\n",
      "Validation Loss: 0.1838, Validation Perplexity: 1.2018\n",
      "Epoch 84/3000, Loss: 0.2055, Perplexity: 1.2281\n",
      "Validation Loss: 0.1729, Validation Perplexity: 1.1887\n",
      "Epoch 85/3000, Loss: 0.1972, Perplexity: 1.2180\n",
      "Validation Loss: 0.1640, Validation Perplexity: 1.1783\n",
      "Epoch 86/3000, Loss: 0.1864, Perplexity: 1.2050\n",
      "Validation Loss: 0.1479, Validation Perplexity: 1.1594\n",
      "Epoch 87/3000, Loss: 0.1730, Perplexity: 1.1888\n",
      "Validation Loss: 0.1522, Validation Perplexity: 1.1644\n",
      "Epoch 88/3000, Loss: 0.1678, Perplexity: 1.1826\n",
      "Validation Loss: 0.1296, Validation Perplexity: 1.1384\n",
      "Epoch 89/3000, Loss: 0.1573, Perplexity: 1.1703\n",
      "Validation Loss: 0.1414, Validation Perplexity: 1.1518\n",
      "Epoch 90/3000, Loss: 0.1531, Perplexity: 1.1655\n",
      "Validation Loss: 0.1256, Validation Perplexity: 1.1338\n",
      "Epoch 91/3000, Loss: 0.1456, Perplexity: 1.1568\n",
      "Validation Loss: 0.1375, Validation Perplexity: 1.1474\n",
      "Epoch 92/3000, Loss: 0.1589, Perplexity: 1.1722\n",
      "Validation Loss: 0.1823, Validation Perplexity: 1.2000\n",
      "Epoch 93/3000, Loss: 0.1801, Perplexity: 1.1973\n",
      "Validation Loss: 0.1244, Validation Perplexity: 1.1325\n",
      "Epoch 94/3000, Loss: 0.1407, Perplexity: 1.1511\n",
      "Validation Loss: 0.1304, Validation Perplexity: 1.1393\n",
      "Epoch 95/3000, Loss: 0.1544, Perplexity: 1.1669\n",
      "Validation Loss: 0.1042, Validation Perplexity: 1.1098\n",
      "Epoch 96/3000, Loss: 0.1258, Perplexity: 1.1341\n",
      "Validation Loss: 0.1389, Validation Perplexity: 1.1490\n",
      "Epoch 97/3000, Loss: 0.1491, Perplexity: 1.1608\n",
      "Validation Loss: 0.1130, Validation Perplexity: 1.1197\n",
      "Epoch 98/3000, Loss: 0.1217, Perplexity: 1.1294\n",
      "Validation Loss: 0.0964, Validation Perplexity: 1.1012\n",
      "Epoch 99/3000, Loss: 0.1144, Perplexity: 1.1212\n",
      "Validation Loss: 0.0975, Validation Perplexity: 1.1025\n",
      "Epoch 100/3000, Loss: 0.1117, Perplexity: 1.1182\n",
      "Validation Loss: 0.0882, Validation Perplexity: 1.0922\n",
      "Epoch 101/3000, Loss: 0.0989, Perplexity: 1.1040\n",
      "Validation Loss: 0.0846, Validation Perplexity: 1.0883\n",
      "Epoch 102/3000, Loss: 0.1017, Perplexity: 1.1071\n",
      "Validation Loss: 0.0803, Validation Perplexity: 1.0837\n",
      "Epoch 103/3000, Loss: 0.0941, Perplexity: 1.0986\n",
      "Validation Loss: 0.0727, Validation Perplexity: 1.0754\n",
      "Epoch 104/3000, Loss: 0.0858, Perplexity: 1.0896\n",
      "Validation Loss: 0.0691, Validation Perplexity: 1.0715\n",
      "Epoch 105/3000, Loss: 0.0840, Perplexity: 1.0876\n",
      "Validation Loss: 0.0669, Validation Perplexity: 1.0692\n",
      "Epoch 106/3000, Loss: 0.0784, Perplexity: 1.0816\n",
      "Validation Loss: 0.0647, Validation Perplexity: 1.0669\n",
      "Epoch 107/3000, Loss: 0.0791, Perplexity: 1.0823\n",
      "Validation Loss: 0.0576, Validation Perplexity: 1.0593\n",
      "Epoch 108/3000, Loss: 0.0713, Perplexity: 1.0739\n",
      "Validation Loss: 0.0595, Validation Perplexity: 1.0613\n",
      "Epoch 109/3000, Loss: 0.0712, Perplexity: 1.0738\n",
      "Validation Loss: 0.0592, Validation Perplexity: 1.0610\n",
      "Epoch 110/3000, Loss: 0.0670, Perplexity: 1.0693\n",
      "Validation Loss: 0.0529, Validation Perplexity: 1.0544\n",
      "Epoch 111/3000, Loss: 0.0636, Perplexity: 1.0656\n",
      "Validation Loss: 0.0517, Validation Perplexity: 1.0531\n",
      "Epoch 112/3000, Loss: 0.0622, Perplexity: 1.0642\n",
      "Validation Loss: 0.0492, Validation Perplexity: 1.0505\n",
      "Epoch 113/3000, Loss: 0.0586, Perplexity: 1.0604\n",
      "Validation Loss: 0.0468, Validation Perplexity: 1.0479\n",
      "Epoch 114/3000, Loss: 0.0587, Perplexity: 1.0605\n",
      "Validation Loss: 0.0468, Validation Perplexity: 1.0479\n",
      "Epoch 115/3000, Loss: 0.0526, Perplexity: 1.0540\n",
      "Validation Loss: 0.0420, Validation Perplexity: 1.0429\n",
      "Epoch 116/3000, Loss: 0.0500, Perplexity: 1.0513\n",
      "Validation Loss: 0.0384, Validation Perplexity: 1.0392\n",
      "Epoch 117/3000, Loss: 0.0486, Perplexity: 1.0498\n",
      "Validation Loss: 0.0407, Validation Perplexity: 1.0415\n",
      "Epoch 118/3000, Loss: 0.0470, Perplexity: 1.0481\n",
      "Validation Loss: 0.0379, Validation Perplexity: 1.0386\n",
      "Epoch 119/3000, Loss: 0.0448, Perplexity: 1.0459\n",
      "Validation Loss: 0.0394, Validation Perplexity: 1.0402\n",
      "Epoch 120/3000, Loss: 0.0467, Perplexity: 1.0478\n",
      "Validation Loss: 0.0384, Validation Perplexity: 1.0392\n",
      "Epoch 121/3000, Loss: 0.0475, Perplexity: 1.0486\n",
      "Validation Loss: 0.0427, Validation Perplexity: 1.0436\n",
      "Epoch 122/3000, Loss: 0.0451, Perplexity: 1.0461\n",
      "Validation Loss: 0.0318, Validation Perplexity: 1.0323\n",
      "Epoch 123/3000, Loss: 0.0439, Perplexity: 1.0448\n",
      "Validation Loss: 0.0343, Validation Perplexity: 1.0349\n",
      "Epoch 124/3000, Loss: 0.0381, Perplexity: 1.0389\n",
      "Validation Loss: 0.0402, Validation Perplexity: 1.0410\n",
      "Epoch 125/3000, Loss: 0.0426, Perplexity: 1.0435\n",
      "Validation Loss: 0.0289, Validation Perplexity: 1.0293\n",
      "Epoch 126/3000, Loss: 0.0371, Perplexity: 1.0378\n",
      "Validation Loss: 0.0292, Validation Perplexity: 1.0296\n",
      "Epoch 127/3000, Loss: 0.0391, Perplexity: 1.0399\n",
      "Validation Loss: 0.0300, Validation Perplexity: 1.0304\n",
      "Epoch 128/3000, Loss: 0.0357, Perplexity: 1.0363\n",
      "Validation Loss: 0.0325, Validation Perplexity: 1.0330\n",
      "Epoch 129/3000, Loss: 0.0363, Perplexity: 1.0369\n",
      "Validation Loss: 0.0264, Validation Perplexity: 1.0268\n",
      "Epoch 130/3000, Loss: 0.0338, Perplexity: 1.0344\n",
      "Validation Loss: 0.0249, Validation Perplexity: 1.0252\n",
      "Epoch 131/3000, Loss: 0.0340, Perplexity: 1.0346\n",
      "Validation Loss: 0.0259, Validation Perplexity: 1.0262\n",
      "Epoch 132/3000, Loss: 0.0333, Perplexity: 1.0339\n",
      "Validation Loss: 0.0267, Validation Perplexity: 1.0270\n",
      "Epoch 133/3000, Loss: 0.0315, Perplexity: 1.0320\n",
      "Validation Loss: 0.0282, Validation Perplexity: 1.0286\n",
      "Epoch 134/3000, Loss: 0.0322, Perplexity: 1.0327\n",
      "Validation Loss: 0.0220, Validation Perplexity: 1.0223\n",
      "Epoch 135/3000, Loss: 0.0304, Perplexity: 1.0308\n",
      "Validation Loss: 0.0239, Validation Perplexity: 1.0242\n",
      "Epoch 136/3000, Loss: 0.0314, Perplexity: 1.0319\n",
      "Validation Loss: 0.0229, Validation Perplexity: 1.0232\n",
      "Epoch 137/3000, Loss: 0.0292, Perplexity: 1.0296\n",
      "Validation Loss: 0.0231, Validation Perplexity: 1.0234\n",
      "Epoch 138/3000, Loss: 0.0267, Perplexity: 1.0270\n",
      "Validation Loss: 0.0299, Validation Perplexity: 1.0304\n",
      "Epoch 139/3000, Loss: 0.0316, Perplexity: 1.0321\n",
      "Validation Loss: 0.0222, Validation Perplexity: 1.0224\n",
      "Epoch 140/3000, Loss: 0.0250, Perplexity: 1.0254\n",
      "Validation Loss: 0.0233, Validation Perplexity: 1.0236\n",
      "Epoch 141/3000, Loss: 0.0349, Perplexity: 1.0355\n",
      "Validation Loss: 0.0223, Validation Perplexity: 1.0225\n",
      "Epoch 142/3000, Loss: 0.0306, Perplexity: 1.0311\n",
      "Validation Loss: 0.0212, Validation Perplexity: 1.0214\n",
      "Epoch 143/3000, Loss: 0.0261, Perplexity: 1.0264\n",
      "Validation Loss: 0.0208, Validation Perplexity: 1.0210\n",
      "Epoch 144/3000, Loss: 0.0252, Perplexity: 1.0255\n",
      "Validation Loss: 0.0211, Validation Perplexity: 1.0213\n",
      "Epoch 145/3000, Loss: 0.0250, Perplexity: 1.0253\n",
      "Validation Loss: 0.0218, Validation Perplexity: 1.0220\n",
      "Epoch 146/3000, Loss: 0.0242, Perplexity: 1.0245\n",
      "Validation Loss: 0.0222, Validation Perplexity: 1.0224\n",
      "Epoch 147/3000, Loss: 0.0251, Perplexity: 1.0254\n",
      "Validation Loss: 0.0218, Validation Perplexity: 1.0221\n",
      "Epoch 148/3000, Loss: 0.0240, Perplexity: 1.0243\n",
      "Validation Loss: 0.0210, Validation Perplexity: 1.0212\n",
      "Epoch 149/3000, Loss: 0.0247, Perplexity: 1.0250\n",
      "Validation Loss: 0.0203, Validation Perplexity: 1.0205\n",
      "Epoch 150/3000, Loss: 0.0235, Perplexity: 1.0237\n",
      "Validation Loss: 0.0199, Validation Perplexity: 1.0201\n",
      "Epoch 151/3000, Loss: 0.0240, Perplexity: 1.0243\n",
      "Validation Loss: 0.0197, Validation Perplexity: 1.0199\n",
      "Epoch 152/3000, Loss: 0.0235, Perplexity: 1.0237\n",
      "Validation Loss: 0.0196, Validation Perplexity: 1.0198\n",
      "Epoch 153/3000, Loss: 0.0230, Perplexity: 1.0232\n",
      "Validation Loss: 0.0194, Validation Perplexity: 1.0196\n",
      "Epoch 154/3000, Loss: 0.0235, Perplexity: 1.0238\n",
      "Validation Loss: 0.0192, Validation Perplexity: 1.0194\n",
      "Epoch 155/3000, Loss: 0.0230, Perplexity: 1.0232\n",
      "Validation Loss: 0.0190, Validation Perplexity: 1.0192\n",
      "Epoch 156/3000, Loss: 0.0219, Perplexity: 1.0222\n",
      "Validation Loss: 0.0188, Validation Perplexity: 1.0190\n",
      "Epoch 157/3000, Loss: 0.0224, Perplexity: 1.0226\n",
      "Validation Loss: 0.0186, Validation Perplexity: 1.0187\n",
      "Epoch 158/3000, Loss: 0.0222, Perplexity: 1.0224\n",
      "Validation Loss: 0.0184, Validation Perplexity: 1.0186\n",
      "Epoch 159/3000, Loss: 0.0221, Perplexity: 1.0224\n",
      "Validation Loss: 0.0183, Validation Perplexity: 1.0185\n",
      "Epoch 160/3000, Loss: 0.0226, Perplexity: 1.0228\n",
      "Validation Loss: 0.0182, Validation Perplexity: 1.0184\n",
      "Epoch 161/3000, Loss: 0.0218, Perplexity: 1.0220\n",
      "Validation Loss: 0.0182, Validation Perplexity: 1.0183\n",
      "Epoch 162/3000, Loss: 0.0227, Perplexity: 1.0229\n",
      "Validation Loss: 0.0181, Validation Perplexity: 1.0183\n",
      "Epoch 163/3000, Loss: 0.0221, Perplexity: 1.0224\n",
      "Validation Loss: 0.0181, Validation Perplexity: 1.0182\n",
      "Epoch 164/3000, Loss: 0.0220, Perplexity: 1.0223\n",
      "Validation Loss: 0.0180, Validation Perplexity: 1.0182\n",
      "Epoch 165/3000, Loss: 0.0222, Perplexity: 1.0224\n",
      "Validation Loss: 0.0180, Validation Perplexity: 1.0182\n",
      "Epoch 166/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0180, Validation Perplexity: 1.0182\n",
      "Epoch 167/3000, Loss: 0.0216, Perplexity: 1.0218\n",
      "Validation Loss: 0.0179, Validation Perplexity: 1.0181\n",
      "Epoch 168/3000, Loss: 0.0210, Perplexity: 1.0213\n",
      "Validation Loss: 0.0178, Validation Perplexity: 1.0180\n",
      "Epoch 169/3000, Loss: 0.0213, Perplexity: 1.0215\n",
      "Validation Loss: 0.0177, Validation Perplexity: 1.0179\n",
      "Epoch 170/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0176, Validation Perplexity: 1.0178\n",
      "Epoch 171/3000, Loss: 0.0213, Perplexity: 1.0216\n",
      "Validation Loss: 0.0176, Validation Perplexity: 1.0177\n",
      "Epoch 172/3000, Loss: 0.0217, Perplexity: 1.0219\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0177\n",
      "Epoch 173/3000, Loss: 0.0224, Perplexity: 1.0226\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0177\n",
      "Epoch 174/3000, Loss: 0.0217, Perplexity: 1.0219\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0176\n",
      "Epoch 175/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0177\n",
      "Epoch 176/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0177\n",
      "Epoch 177/3000, Loss: 0.0216, Perplexity: 1.0218\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0177\n",
      "Epoch 178/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0175, Validation Perplexity: 1.0176\n",
      "Epoch 179/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0174, Validation Perplexity: 1.0176\n",
      "Epoch 180/3000, Loss: 0.0212, Perplexity: 1.0215\n",
      "Validation Loss: 0.0174, Validation Perplexity: 1.0176\n",
      "Epoch 181/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0174, Validation Perplexity: 1.0175\n",
      "Epoch 182/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0173, Validation Perplexity: 1.0174\n",
      "Epoch 183/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0172, Validation Perplexity: 1.0174\n",
      "Epoch 184/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0172, Validation Perplexity: 1.0174\n",
      "Epoch 185/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0172, Validation Perplexity: 1.0174\n",
      "Epoch 186/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0173, Validation Perplexity: 1.0174\n",
      "Epoch 187/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0173, Validation Perplexity: 1.0174\n",
      "Epoch 188/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0171, Validation Perplexity: 1.0173\n",
      "Epoch 189/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0170, Validation Perplexity: 1.0171\n",
      "Epoch 190/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0170\n",
      "Epoch 191/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0170\n",
      "Epoch 192/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 193/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0170\n",
      "Epoch 194/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0171\n",
      "Epoch 195/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0170, Validation Perplexity: 1.0172\n",
      "Epoch 196/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0170, Validation Perplexity: 1.0172\n",
      "Epoch 197/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0170, Validation Perplexity: 1.0172\n",
      "Epoch 198/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0171\n",
      "Epoch 199/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0171\n",
      "Epoch 200/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0171\n",
      "Epoch 201/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0170\n",
      "Epoch 202/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0170\n",
      "Epoch 203/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0169, Validation Perplexity: 1.0170\n",
      "Epoch 204/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 205/3000, Loss: 0.0193, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 206/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 207/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 208/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 209/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 210/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 211/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 212/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 213/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 214/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 215/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 216/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 217/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 218/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 219/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 220/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 221/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 222/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 223/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 224/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 225/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 226/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 227/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 228/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 229/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 230/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 231/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 232/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 233/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 234/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 235/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 236/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 237/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 238/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 239/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 240/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 241/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 242/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 243/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 244/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 245/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 246/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 247/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 248/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 249/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 250/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 251/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 252/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 253/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 254/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 255/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 256/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 257/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 258/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 259/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 260/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 261/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 262/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 263/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 264/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 265/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 266/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 267/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 268/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 269/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 270/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 271/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 272/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 273/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 274/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 275/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 276/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 277/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 278/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 279/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 280/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 281/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 282/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 283/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 284/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 285/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 286/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 287/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 288/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 289/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 290/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 291/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 292/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 293/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 294/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 295/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 296/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 297/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 298/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 299/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 300/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 301/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 302/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 303/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 304/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 305/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 306/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 307/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 308/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 309/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 310/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 311/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 312/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 313/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 314/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 315/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 316/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 317/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 318/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 319/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 320/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 321/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 322/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 323/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 324/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 325/3000, Loss: 0.0195, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 326/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 327/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 328/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 329/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 330/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 331/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 332/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 333/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 334/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 335/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 336/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 337/3000, Loss: 0.0207, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 338/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 339/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 340/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 341/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 342/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 343/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 344/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 345/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 346/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 347/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 348/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 349/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 350/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 351/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 352/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 353/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 354/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 355/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 356/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 357/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 358/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 359/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 360/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 361/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 362/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 363/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 364/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 365/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 366/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 367/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 368/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 369/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 370/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 371/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 372/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 373/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 374/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 375/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 376/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 377/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 378/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 379/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 380/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 381/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 382/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 383/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 384/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 385/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 386/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 387/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 388/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 389/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 390/3000, Loss: 0.0211, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 391/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 392/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 393/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 394/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 395/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 396/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 397/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 398/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 399/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 400/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 401/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 402/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 403/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 404/3000, Loss: 0.0200, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 405/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 406/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 407/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 408/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 409/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 410/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 411/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 412/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 413/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 414/3000, Loss: 0.0214, Perplexity: 1.0217\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 415/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 416/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 417/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 418/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 419/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 420/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 421/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 422/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 423/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 424/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 425/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 426/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 427/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 428/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 429/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 430/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 431/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 432/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 433/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 434/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 435/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 436/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 437/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 438/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 439/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 440/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 441/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 442/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 443/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 444/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 445/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 446/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 447/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 448/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 449/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 450/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 451/3000, Loss: 0.0194, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 452/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 453/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 454/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 455/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 456/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 457/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 458/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 459/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 460/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 461/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 462/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 463/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 464/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 465/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 466/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 467/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 468/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 469/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 470/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 471/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 472/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 473/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 474/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 475/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 476/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 477/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 478/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 479/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 480/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 481/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 482/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 483/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 484/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 485/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 486/3000, Loss: 0.0210, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 487/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 488/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 489/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 490/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 491/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 492/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 493/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 494/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 495/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 496/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 497/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 498/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 499/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 500/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 501/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 502/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 503/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 504/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 505/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 506/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 507/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 508/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 509/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 510/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 511/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 512/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 513/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 514/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 515/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 516/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 517/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 518/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 519/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 520/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 521/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 522/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 523/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 524/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 525/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 526/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 527/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 528/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 529/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 530/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 531/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 532/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 533/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 534/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 535/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 536/3000, Loss: 0.0213, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 537/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 538/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 539/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 540/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 541/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 542/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 543/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 544/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 545/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 546/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 547/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 548/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 549/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 550/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 551/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 552/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 553/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 554/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 555/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 556/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 557/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 558/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 559/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 560/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 561/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 562/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 563/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 564/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 565/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 566/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 567/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 568/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 569/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 570/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 571/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 572/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 573/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 574/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 575/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 576/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 577/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 578/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 579/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 580/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 581/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 582/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 583/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 584/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 585/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 586/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 587/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 588/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 589/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 590/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 591/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 592/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 593/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 594/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 595/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 596/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 597/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 598/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 599/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 600/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 601/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 602/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 603/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 604/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 605/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 606/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 607/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 608/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 609/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 610/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 611/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 612/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 613/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 614/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 615/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 616/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 617/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 618/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 619/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 620/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 621/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 622/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 623/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 624/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 625/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 626/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 627/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 628/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 629/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 630/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 631/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 632/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 633/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 634/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 635/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 636/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 637/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 638/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 639/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 640/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 641/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 642/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 643/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 644/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 645/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 646/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 647/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 648/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 649/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 650/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 651/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 652/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 653/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 654/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 655/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 656/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 657/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 658/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 659/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 660/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 661/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 662/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 663/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 664/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 665/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 666/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 667/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 668/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 669/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 670/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 671/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 672/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 673/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 674/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 675/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 676/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 677/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 678/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 679/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 680/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 681/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 682/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 683/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 684/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 685/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 686/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 687/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 688/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 689/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 690/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 691/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 692/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 693/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 694/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 695/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 696/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 697/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 698/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 699/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 700/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 701/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 702/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 703/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 704/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 705/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 706/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 707/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 708/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 709/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 710/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 711/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 712/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 713/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 714/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 715/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 716/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 717/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 718/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 719/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 720/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 721/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 722/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 723/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 724/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 725/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 726/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 727/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 728/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 729/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 730/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 731/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 732/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 733/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 734/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 735/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 736/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 737/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 738/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 739/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 740/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 741/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 742/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 743/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 744/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 745/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 746/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 747/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 748/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 749/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 750/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 751/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 752/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 753/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 754/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 755/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 756/3000, Loss: 0.0212, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 757/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 758/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 759/3000, Loss: 0.0214, Perplexity: 1.0216\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 760/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 761/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 762/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 763/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 764/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 765/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 766/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 767/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 768/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 769/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 770/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 771/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 772/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 773/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 774/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 775/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 776/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 777/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 778/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 779/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 780/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 781/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 782/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 783/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 784/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 785/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 786/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 787/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 788/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 789/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 790/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 791/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 792/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 793/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 794/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 795/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 796/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 797/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 798/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 799/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 800/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 801/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 802/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 803/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 804/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 805/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 806/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 807/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 808/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 809/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 810/3000, Loss: 0.0200, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 811/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 812/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 813/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 814/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 815/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 816/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 817/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 818/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 819/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 820/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 821/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 822/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 823/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 824/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 825/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 826/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 827/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 828/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 829/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 830/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 831/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 832/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 833/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 834/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 835/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 836/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 837/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 838/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 839/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 840/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 841/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 842/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 843/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 844/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 845/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 846/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 847/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 848/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 849/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 850/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 851/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 852/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 853/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 854/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 855/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 856/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 857/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 858/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 859/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 860/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 861/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 862/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 863/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 864/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 865/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 866/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 867/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 868/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 869/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 870/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 871/3000, Loss: 0.0191, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 872/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 873/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 874/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 875/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 876/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 877/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 878/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 879/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 880/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 881/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 882/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 883/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 884/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 885/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0170\n",
      "Epoch 886/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 887/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 888/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 889/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 890/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 891/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 892/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 893/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 894/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 895/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 896/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 897/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 898/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 899/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 900/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 901/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 902/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 903/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 904/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 905/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 906/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 907/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 908/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 909/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 910/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 911/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 912/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 913/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 914/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 915/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 916/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 917/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 918/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 919/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 920/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 921/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 922/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 923/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 924/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 925/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 926/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 927/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 928/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 929/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 930/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 931/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 932/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 933/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 934/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 935/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 936/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 937/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 938/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 939/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 940/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 941/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 942/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 943/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 944/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 945/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 946/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 947/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 948/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 949/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 950/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 951/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 952/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 953/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 954/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 955/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 956/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 957/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 958/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 959/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 960/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 961/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 962/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 963/3000, Loss: 0.0200, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 964/3000, Loss: 0.0194, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 965/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 966/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 967/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 968/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 969/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 970/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 971/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 972/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 973/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 974/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 975/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 976/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 977/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 978/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 979/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 980/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 981/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 982/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 983/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 984/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 985/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 986/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 987/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 988/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 989/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 990/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 991/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 992/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 993/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 994/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 995/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 996/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 997/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 998/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 999/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1000/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1001/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1002/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1003/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1004/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1005/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1006/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1007/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1008/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1009/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1010/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1011/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1012/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1013/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1014/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1015/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1016/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1017/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1018/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1019/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1020/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1021/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1022/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1023/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1024/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1025/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1026/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1027/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1028/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1029/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1030/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1031/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1032/3000, Loss: 0.0191, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1033/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1034/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1035/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1036/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1037/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1038/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1039/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1040/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1041/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1042/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1043/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1044/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1045/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1046/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1047/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1048/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1049/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1050/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1051/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1052/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1053/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1054/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1055/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1056/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1057/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1058/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1059/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1060/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1061/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1062/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1063/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1064/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1065/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1066/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1067/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1068/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1069/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1070/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1071/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1072/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1073/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1074/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1075/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1076/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1077/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1078/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1079/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1080/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1081/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1082/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1083/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1084/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1085/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1086/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1087/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1088/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1089/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1090/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1091/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1092/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1093/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1094/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1095/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1096/3000, Loss: 0.0212, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1097/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1098/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1099/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1100/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1101/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1102/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1103/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1104/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1105/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1106/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1107/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1108/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1109/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1110/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1111/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1112/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1113/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1114/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1115/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1116/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1117/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1118/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1119/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1120/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1121/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1122/3000, Loss: 0.0191, Perplexity: 1.0192\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1123/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1124/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1125/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1126/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1127/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1128/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1129/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1130/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1131/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1132/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1133/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1134/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1135/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1136/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1137/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1138/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1139/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1140/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1141/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1142/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1143/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1144/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1145/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1146/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1147/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1148/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1149/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1150/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1151/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1152/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1153/3000, Loss: 0.0190, Perplexity: 1.0192\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1154/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1155/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1156/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1157/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1158/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1159/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1160/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1161/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1162/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1163/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1164/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1165/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1166/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1167/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1168/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1169/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1170/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1171/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1172/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1173/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1174/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1175/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1176/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1177/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1178/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1179/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1180/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1181/3000, Loss: 0.0194, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1182/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1183/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1184/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1185/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1186/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1187/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1188/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1189/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1190/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1191/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1192/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1193/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1194/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1195/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1196/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1197/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1198/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1199/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1200/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1201/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1202/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1203/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1204/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1205/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1206/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1207/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1208/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1209/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1210/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1211/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1212/3000, Loss: 0.0200, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1213/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1214/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1215/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1216/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1217/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1218/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1219/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1220/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1221/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1222/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1223/3000, Loss: 0.0211, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1224/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1225/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1226/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1227/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1228/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1229/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1230/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1231/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1232/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1233/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1234/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1235/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1236/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1237/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1238/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1239/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1240/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1241/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1242/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1243/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1244/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1245/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1246/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1247/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1248/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1249/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1250/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1251/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1252/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1253/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1254/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1255/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1256/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1257/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1258/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1259/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1260/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1261/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1262/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1263/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1264/3000, Loss: 0.0200, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1265/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1266/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1267/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1268/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1269/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1270/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1271/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1272/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1273/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1274/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1275/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1276/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1277/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1278/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1279/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1280/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1281/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1282/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1283/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1284/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1285/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1286/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1287/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1288/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1289/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1290/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1291/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1292/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1293/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1294/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1295/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1296/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1297/3000, Loss: 0.0192, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1298/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1299/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1300/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1301/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1302/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1303/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1304/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1305/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1306/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1307/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1308/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1309/3000, Loss: 0.0190, Perplexity: 1.0192\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1310/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1311/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1312/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1313/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1314/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1315/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1316/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1317/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1318/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1319/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1320/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1321/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1322/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1323/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1324/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1325/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1326/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1327/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1328/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1329/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1330/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1331/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1332/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1333/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1334/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1335/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1336/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1337/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1338/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1339/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1340/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1341/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1342/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1343/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1344/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1345/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1346/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1347/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1348/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1349/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1350/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1351/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1352/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1353/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1354/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1355/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1356/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1357/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1358/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1359/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1360/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1361/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1362/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1363/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1364/3000, Loss: 0.0192, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1365/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1366/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1367/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1368/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1369/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1370/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1371/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1372/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1373/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1374/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1375/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1376/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1377/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1378/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1379/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1380/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1381/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1382/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1383/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1384/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1385/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1386/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1387/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1388/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1389/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1390/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1391/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1392/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1393/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1394/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1395/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1396/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1397/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1398/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1399/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1400/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1401/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1402/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1403/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1404/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1405/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1406/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1407/3000, Loss: 0.0210, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1408/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1409/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1410/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1411/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1412/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1413/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1414/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1415/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1416/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1417/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1418/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1419/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1420/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1421/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1422/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1423/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1424/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1425/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1426/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1427/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1428/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1429/3000, Loss: 0.0192, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1430/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1431/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1432/3000, Loss: 0.0216, Perplexity: 1.0218\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1433/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1434/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1435/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1436/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1437/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1438/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1439/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1440/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1441/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1442/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1443/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1444/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1445/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1446/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1447/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1448/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1449/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1450/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1451/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1452/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1453/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1454/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1455/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1456/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1457/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1458/3000, Loss: 0.0190, Perplexity: 1.0192\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1459/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1460/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1461/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1462/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1463/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1464/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1465/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1466/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1467/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1468/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1469/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1470/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1471/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1472/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1473/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1474/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1475/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1476/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1477/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1478/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1479/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1480/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1481/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1482/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1483/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1484/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1485/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1486/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1487/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1488/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1489/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1490/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1491/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1492/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1493/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1494/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1495/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1496/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1497/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1498/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1499/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1500/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1501/3000, Loss: 0.0194, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1502/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1503/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1504/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1505/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1506/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1507/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1508/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1509/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1510/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1511/3000, Loss: 0.0210, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1512/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1513/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1514/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1515/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1516/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1517/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1518/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1519/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1520/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1521/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1522/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1523/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1524/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1525/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1526/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1527/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1528/3000, Loss: 0.0192, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1529/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1530/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1531/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1532/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1533/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1534/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1535/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1536/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1537/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1538/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1539/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1540/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1541/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1542/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1543/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1544/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1545/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1546/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1547/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1548/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1549/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1550/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1551/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1552/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1553/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1554/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1555/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1556/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1557/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1558/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1559/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1560/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1561/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1562/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1563/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1564/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1565/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1566/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1567/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1568/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1569/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1570/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1571/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1572/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1573/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1574/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1575/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1576/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1577/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1578/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1579/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1580/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1581/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1582/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1583/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1584/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1585/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1586/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1587/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1588/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1589/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1590/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1591/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1592/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1593/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1594/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1595/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1596/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1597/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1598/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1599/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1600/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1601/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1602/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1603/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1604/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1605/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1606/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1607/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1608/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1609/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1610/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1611/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1612/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1613/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1614/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1615/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1616/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1617/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1618/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1619/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1620/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1621/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1622/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1623/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1624/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1625/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1626/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1627/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1628/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1629/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1630/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1631/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1632/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1633/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1634/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1635/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1636/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1637/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1638/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1639/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1640/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1641/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1642/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1643/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1644/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1645/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1646/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1647/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1648/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1649/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1650/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1651/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1652/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1653/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1654/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1655/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1656/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1657/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1658/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1659/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1660/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1661/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1662/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1663/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1664/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1665/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1666/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1667/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1668/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1669/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1670/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1671/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1672/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1673/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1674/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1675/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1676/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1677/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1678/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1679/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1680/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1681/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1682/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1683/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1684/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1685/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1686/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1687/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1688/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1689/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1690/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1691/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1692/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1693/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1694/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1695/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1696/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1697/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1698/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1699/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1700/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1701/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1702/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1703/3000, Loss: 0.0214, Perplexity: 1.0216\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1704/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1705/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1706/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1707/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1708/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1709/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1710/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1711/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1712/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1713/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1714/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1715/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1716/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1717/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1718/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1719/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1720/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1721/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1722/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1723/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1724/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1725/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1726/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1727/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1728/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1729/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1730/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1731/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1732/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1733/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1734/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1735/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1736/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1737/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1738/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1739/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1740/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1741/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1742/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1743/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1744/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1745/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1746/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1747/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1748/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1749/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1750/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1751/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1752/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1753/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1754/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1755/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1756/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1757/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1758/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1759/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1760/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1761/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1762/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1763/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1764/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1765/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1766/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1767/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1768/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1769/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1770/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1771/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1772/3000, Loss: 0.0207, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1773/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1774/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1775/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1776/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1777/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1778/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1779/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1780/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1781/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1782/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1783/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1784/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1785/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1786/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1787/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1788/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1789/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1790/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1791/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1792/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1793/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1794/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1795/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1796/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1797/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1798/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1799/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1800/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1801/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1802/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1803/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1804/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1805/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1806/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1807/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1808/3000, Loss: 0.0213, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1809/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1810/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1811/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1812/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1813/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1814/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1815/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1816/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1817/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1818/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1819/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1820/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1821/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1822/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1823/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1824/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1825/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1826/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1827/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1828/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1829/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1830/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1831/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1832/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1833/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1834/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1835/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1836/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1837/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1838/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1839/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1840/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1841/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1842/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1843/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1844/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1845/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1846/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1847/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1848/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1849/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1850/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1851/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1852/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1853/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1854/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1855/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1856/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1857/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1858/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1859/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1860/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1861/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1862/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1863/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1864/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1865/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1866/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1867/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1868/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1869/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1870/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1871/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1872/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1873/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1874/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1875/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1876/3000, Loss: 0.0191, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1877/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1878/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1879/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1880/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1881/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1882/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1883/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1884/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1885/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1886/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1887/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1888/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1889/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1890/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1891/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1892/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1893/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1894/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1895/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1896/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1897/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1898/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1899/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1900/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1901/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1902/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1903/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1904/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1905/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1906/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1907/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1908/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1909/3000, Loss: 0.0192, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1910/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1911/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1912/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1913/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1914/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1915/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1916/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1917/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1918/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1919/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1920/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1921/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1922/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1923/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1924/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1925/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1926/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1927/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1928/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1929/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1930/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1931/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1932/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1933/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1934/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1935/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1936/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1937/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1938/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1939/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1940/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1941/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1942/3000, Loss: 0.0211, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1943/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1944/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1945/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1946/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1947/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1948/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1949/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1950/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1951/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1952/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1953/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1954/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1955/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1956/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1957/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1958/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1959/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1960/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1961/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1962/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1963/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1964/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1965/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1966/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1967/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1968/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1969/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1970/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1971/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1972/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1973/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1974/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1975/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1976/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1977/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1978/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1979/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1980/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1981/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1982/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1983/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1984/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1985/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1986/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1987/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1988/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1989/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1990/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1991/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1992/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1993/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1994/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1995/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1996/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1997/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1998/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 1999/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2000/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2001/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2002/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2003/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2004/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2005/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2006/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2007/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2008/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2009/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2010/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2011/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2012/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2013/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2014/3000, Loss: 0.0207, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2015/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2016/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2017/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2018/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2019/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2020/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2021/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2022/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2023/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2024/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2025/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2026/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2027/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2028/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2029/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2030/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2031/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2032/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2033/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2034/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2035/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2036/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2037/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2038/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2039/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2040/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2041/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2042/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2043/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2044/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2045/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2046/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2047/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2048/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2049/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2050/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2051/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2052/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2053/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2054/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2055/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2056/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2057/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2058/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2059/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2060/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2061/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2062/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2063/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2064/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2065/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2066/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2067/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2068/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2069/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2070/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2071/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2072/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2073/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2074/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2075/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2076/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2077/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2078/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2079/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2080/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2081/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2082/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2083/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2084/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2085/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2086/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2087/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2088/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2089/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2090/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2091/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2092/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2093/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2094/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2095/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2096/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2097/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2098/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2099/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2100/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2101/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2102/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2103/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2104/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2105/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2106/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2107/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2108/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2109/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2110/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2111/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2112/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2113/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2114/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2115/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2116/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2117/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2118/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2119/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2120/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2121/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2122/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2123/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2124/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2125/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2126/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2127/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2128/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2129/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2130/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2131/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2132/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2133/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2134/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2135/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2136/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2137/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2138/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2139/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2140/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2141/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2142/3000, Loss: 0.0207, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2143/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2144/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2145/3000, Loss: 0.0199, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2146/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2147/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2148/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2149/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2150/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2151/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2152/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2153/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2154/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2155/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2156/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2157/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2158/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2159/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2160/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2161/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2162/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2163/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2164/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2165/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2166/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2167/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2168/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2169/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2170/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2171/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2172/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2173/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2174/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2175/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2176/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2177/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2178/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2179/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2180/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2181/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2182/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2183/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2184/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2185/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2186/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2187/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2188/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2189/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2190/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2191/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2192/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2193/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2194/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2195/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2196/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2197/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2198/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2199/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2200/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2201/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2202/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2203/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2204/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2205/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2206/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2207/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2208/3000, Loss: 0.0212, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2209/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2210/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2211/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2212/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2213/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2214/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2215/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2216/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2217/3000, Loss: 0.0210, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2218/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2219/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2220/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2221/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2222/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2223/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2224/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2225/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2226/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2227/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2228/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2229/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2230/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2231/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2232/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2233/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2234/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2235/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2236/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2237/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2238/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2239/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2240/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2241/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2242/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2243/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2244/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2245/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2246/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2247/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2248/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2249/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2250/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2251/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2252/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2253/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2254/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2255/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2256/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2257/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2258/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2259/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2260/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2261/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2262/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2263/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2264/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2265/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2266/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2267/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2268/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2269/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2270/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2271/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2272/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2273/3000, Loss: 0.0207, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2274/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2275/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2276/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2277/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2278/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2279/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2280/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2281/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2282/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2283/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2284/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2285/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2286/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2287/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2288/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2289/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2290/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2291/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2292/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2293/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2294/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2295/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2296/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2297/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2298/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2299/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2300/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2301/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2302/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2303/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2304/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2305/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2306/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2307/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2308/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2309/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2310/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2311/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2312/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2313/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2314/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2315/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2316/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2317/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2318/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2319/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2320/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2321/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2322/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2323/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2324/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2325/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2326/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2327/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2328/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2329/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2330/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2331/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2332/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2333/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2334/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2335/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2336/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2337/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2338/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2339/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2340/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2341/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2342/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2343/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2344/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2345/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2346/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2347/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2348/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2349/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2350/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2351/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2352/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2353/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2354/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2355/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2356/3000, Loss: 0.0215, Perplexity: 1.0218\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2357/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2358/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2359/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2360/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2361/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2362/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2363/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2364/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2365/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2366/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2367/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2368/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2369/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2370/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2371/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2372/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2373/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2374/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2375/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2376/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2377/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2378/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2379/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2380/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2381/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2382/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2383/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2384/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2385/3000, Loss: 0.0214, Perplexity: 1.0216\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2386/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2387/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2388/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2389/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2390/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2391/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2392/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2393/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2394/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2395/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2396/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2397/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2398/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2399/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2400/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2401/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2402/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2403/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2404/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2405/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2406/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2407/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2408/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2409/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2410/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2411/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2412/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2413/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2414/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2415/3000, Loss: 0.0211, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2416/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2417/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2418/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2419/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2420/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2421/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2422/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2423/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2424/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2425/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2426/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2427/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2428/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2429/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2430/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2431/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2432/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2433/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2434/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2435/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2436/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2437/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2438/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2439/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2440/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2441/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2442/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2443/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2444/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2445/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2446/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2447/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2448/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2449/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2450/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2451/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2452/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2453/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2454/3000, Loss: 0.0197, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2455/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2456/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2457/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2458/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2459/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2460/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2461/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2462/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2463/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2464/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2465/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2466/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2467/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2468/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2469/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2470/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2471/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2472/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2473/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2474/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2475/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2476/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2477/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2478/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2479/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2480/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2481/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2482/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2483/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2484/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2485/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2486/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2487/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2488/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2489/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2490/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2491/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2492/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2493/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2494/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2495/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2496/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2497/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2498/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2499/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2500/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2501/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2502/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2503/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2504/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2505/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2506/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2507/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2508/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2509/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2510/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2511/3000, Loss: 0.0210, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2512/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2513/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2514/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2515/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2516/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2517/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2518/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2519/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2520/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2521/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2522/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2523/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2524/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2525/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2526/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2527/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2528/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2529/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2530/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2531/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2532/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2533/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2534/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2535/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2536/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2537/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2538/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2539/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2540/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2541/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2542/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2543/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2544/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2545/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2546/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2547/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2548/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2549/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2550/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2551/3000, Loss: 0.0199, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2552/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2553/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2554/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2555/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2556/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2557/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2558/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2559/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2560/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2561/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2562/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2563/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2564/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2565/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2566/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2567/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2568/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2569/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2570/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2571/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2572/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2573/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2574/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2575/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2576/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2577/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2578/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2579/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2580/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2581/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2582/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2583/3000, Loss: 0.0213, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2584/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2585/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2586/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2587/3000, Loss: 0.0208, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2588/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2589/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2590/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2591/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2592/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2593/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2594/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2595/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2596/3000, Loss: 0.0199, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2597/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2598/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2599/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2600/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2601/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2602/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2603/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2604/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2605/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2606/3000, Loss: 0.0191, Perplexity: 1.0193\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2607/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2608/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2609/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2610/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2611/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2612/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2613/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2614/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2615/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2616/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2617/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2618/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2619/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2620/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2621/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2622/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2623/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2624/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2625/3000, Loss: 0.0203, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2626/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2627/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2628/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2629/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2630/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2631/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2632/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2633/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2634/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2635/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2636/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2637/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2638/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2639/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2640/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2641/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2642/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2643/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2644/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2645/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2646/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2647/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2648/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2649/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2650/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2651/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2652/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2653/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2654/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2655/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2656/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2657/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2658/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2659/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2660/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2661/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2662/3000, Loss: 0.0209, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2663/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2664/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2665/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2666/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2667/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2668/3000, Loss: 0.0205, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2669/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2670/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2671/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2672/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2673/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2674/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2675/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2676/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2677/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2678/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2679/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2680/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2681/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2682/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2683/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2684/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2685/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2686/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2687/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2688/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2689/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2690/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2691/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2692/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2693/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2694/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2695/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2696/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2697/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2698/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2699/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2700/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2701/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2702/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2703/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2704/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2705/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2706/3000, Loss: 0.0212, Perplexity: 1.0214\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2707/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2708/3000, Loss: 0.0195, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2709/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2710/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2711/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2712/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2713/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2714/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2715/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2716/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2717/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2718/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2719/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2720/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2721/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2722/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2723/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2724/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2725/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2726/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2727/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2728/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2729/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2730/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2731/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2732/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2733/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2734/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2735/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2736/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2737/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2738/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2739/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2740/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2741/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2742/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2743/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2744/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2745/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2746/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2747/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2748/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2749/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2750/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2751/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2752/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2753/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2754/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2755/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2756/3000, Loss: 0.0194, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2757/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2758/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2759/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2760/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2761/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2762/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2763/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2764/3000, Loss: 0.0196, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2765/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2766/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2767/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2768/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2769/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2770/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2771/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2772/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2773/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2774/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2775/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2776/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2777/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2778/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2779/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2780/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2781/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2782/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2783/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2784/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2785/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2786/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2787/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2788/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2789/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2790/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2791/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2792/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2793/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2794/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2795/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2796/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2797/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2798/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2799/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2800/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2801/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2802/3000, Loss: 0.0202, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2803/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2804/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2805/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2806/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2807/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2808/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2809/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2810/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2811/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2812/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2813/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2814/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2815/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2816/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2817/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2818/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2819/3000, Loss: 0.0207, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2820/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2821/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2822/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2823/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2824/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2825/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2826/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2827/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2828/3000, Loss: 0.0215, Perplexity: 1.0217\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2829/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2830/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2831/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2832/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2833/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2834/3000, Loss: 0.0195, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2835/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2836/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2837/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2838/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2839/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2840/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2841/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2842/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2843/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2844/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2845/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2846/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2847/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2848/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2849/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2850/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2851/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2852/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2853/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2854/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2855/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2856/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2857/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2858/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2859/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2860/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2861/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2862/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2863/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2864/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2865/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2866/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2867/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2868/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2869/3000, Loss: 0.0204, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2870/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2871/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2872/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2873/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2874/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2875/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2876/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2877/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2878/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2879/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2880/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2881/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2882/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2883/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2884/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2885/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2886/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2887/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2888/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2889/3000, Loss: 0.0209, Perplexity: 1.0211\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2890/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2891/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2892/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2893/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2894/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2895/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2896/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2897/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2898/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2899/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2900/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2901/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2902/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2903/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2904/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2905/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2906/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2907/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2908/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2909/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2910/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2911/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2912/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2913/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2914/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2915/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2916/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2917/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2918/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2919/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2920/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2921/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2922/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2923/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2924/3000, Loss: 0.0193, Perplexity: 1.0195\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2925/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2926/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2927/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2928/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2929/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2930/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2931/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2932/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2933/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2934/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2935/3000, Loss: 0.0211, Perplexity: 1.0213\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2936/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2937/3000, Loss: 0.0212, Perplexity: 1.0215\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2938/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2939/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2940/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2941/3000, Loss: 0.0198, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2942/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2943/3000, Loss: 0.0192, Perplexity: 1.0194\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2944/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2945/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2946/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2947/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2948/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2949/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2950/3000, Loss: 0.0195, Perplexity: 1.0197\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2951/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2952/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2953/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2954/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2955/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2956/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2957/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2958/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2959/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2960/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2961/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2962/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2963/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2964/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2965/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2966/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2967/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2968/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2969/3000, Loss: 0.0194, Perplexity: 1.0196\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2970/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2971/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2972/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2973/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2974/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2975/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2976/3000, Loss: 0.0206, Perplexity: 1.0208\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2977/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2978/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2979/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2980/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2981/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2982/3000, Loss: 0.0201, Perplexity: 1.0203\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2983/3000, Loss: 0.0197, Perplexity: 1.0199\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2984/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2985/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2986/3000, Loss: 0.0207, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2987/3000, Loss: 0.0201, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2988/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2989/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2990/3000, Loss: 0.0208, Perplexity: 1.0210\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2991/3000, Loss: 0.0204, Perplexity: 1.0206\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2992/3000, Loss: 0.0206, Perplexity: 1.0209\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2993/3000, Loss: 0.0198, Perplexity: 1.0200\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2994/3000, Loss: 0.0200, Perplexity: 1.0202\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2995/3000, Loss: 0.0203, Perplexity: 1.0205\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2996/3000, Loss: 0.0196, Perplexity: 1.0198\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2997/3000, Loss: 0.0210, Perplexity: 1.0212\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2998/3000, Loss: 0.0199, Perplexity: 1.0201\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 2999/3000, Loss: 0.0202, Perplexity: 1.0204\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n",
      "Epoch 3000/3000, Loss: 0.0205, Perplexity: 1.0207\n",
      "Validation Loss: 0.0168, Validation Perplexity: 1.0169\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "perplexity_train = []\n",
    "perplexity_test = []\n",
    "\n",
    "num_epochs = 3000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    m.train()\n",
    "\n",
    "    inputs, targets = next(iter(data_loader_train))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    logit, loss, perplexity = model(inputs, use='train', y=targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss:.4f}, Perplexity: {perplexity:.4f}\")\n",
    "\n",
    "    # eval \n",
    "    m.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs_t, targets_t = next(iter(data_loader_test))\n",
    "\n",
    "        # Forward pass\n",
    "        logit, valid_loss, valid_perplexity = model(inputs, use='train', y=targets)\n",
    "\n",
    "    print(f\"Validation Loss: {valid_loss:.4f}, Validation Perplexity: {valid_perplexity:.4f}\")\n",
    "\n",
    "\n",
    "    train_loss.append(loss.cpu().detach().numpy())\n",
    "    test_loss.append(valid_loss.cpu().detach().numpy())\n",
    "    perplexity_train.append(perplexity.cpu().detach().numpy())\n",
    "    perplexity_test.append(valid_perplexity.cpu().detach().numpy())\n",
    "\n",
    "    scheduler.step(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x230ecdd0650>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "epoch_list = np.arange(0,len(train_loss))\n",
    "plt.plot(epoch_list,perplexity_train)\n",
    "plt.plot(epoch_list,perplexity_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.01900933, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(0,len(train_loss))\n",
    "plt.plot(epoch_list,train_loss)\n",
    "plt.plot(epoch_list,test_loss)\n",
    "min(train_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\3000_step_decay_with_init_no_shuffle_good.pth\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path \n",
    "MODEL_NAME = \"3000_step_decay_with_init_no_shuffle_good.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict \n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=m.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('models/4000_step_decay_with_init_good.pth')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.load_state_dict(torch.load('models/4000_step_decay_with_init.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6059\n",
      "6060\n",
      "6061\n",
      "6062\n",
      "6063\n",
      "6064\n",
      "6065\n",
      "6066\n",
      "6067\n",
      "6068\n",
      "6069\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6074\n",
      "6075\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6090\n",
      "6091\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6096\n",
      "6097\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6112\n",
      "6113\n",
      "6114\n",
      "6115\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6120\n",
      "6121\n",
      "6122\n",
      "6123\n",
      "6124\n",
      "6125\n",
      "6126\n",
      "6127\n",
      "6128\n",
      "6129\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6148\n",
      "6149\n",
      "6150\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6165\n",
      "6166\n",
      "6167\n",
      "6168\n",
      "6169\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6173\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6178\n",
      "6179\n",
      "6180\n",
      "6181\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6185\n",
      "6186\n",
      "6187\n",
      "6188\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6232\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6238\n",
      "6239\n",
      "6240\n",
      "6241\n",
      "6242\n",
      "6243\n",
      "6244\n",
      "6245\n",
      "6246\n",
      "6247\n",
      "6248\n",
      "6249\n",
      "6250\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6305\n",
      "6306\n",
      "6307\n",
      "6308\n",
      "6309\n",
      "6310\n",
      "6311\n",
      "6312\n",
      "6313\n",
      "6314\n",
      "6315\n",
      "6316\n",
      "6317\n",
      "6318\n",
      "6319\n",
      "6320\n",
      "6321\n",
      "6322\n",
      "6323\n",
      "6324\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6328\n",
      "6329\n",
      "6330\n",
      "6331\n",
      "6332\n",
      "6333\n",
      "6334\n",
      "6335\n",
      "6336\n",
      "6337\n",
      "6338\n",
      "6339\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6343\n",
      "6344\n",
      "6345\n",
      "6346\n",
      "6347\n",
      "6348\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6352\n",
      "6353\n",
      "6354\n",
      "6355\n",
      "6356\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6360\n",
      "6361\n",
      "6362\n",
      "6363\n",
      "6364\n",
      "6365\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6370\n",
      "6371\n",
      "6372\n",
      "6373\n",
      "6374\n",
      "6375\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6380\n",
      "6381\n",
      "6382\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6386\n",
      "6387\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6393\n",
      "6394\n",
      "6395\n",
      "6396\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6400\n",
      "6401\n",
      "6402\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6408\n",
      "6409\n",
      "6410\n",
      "6411\n",
      "6412\n",
      "6413\n",
      "6414\n",
      "6415\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6420\n",
      "6421\n",
      "6422\n",
      "6423\n",
      "6424\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6429\n",
      "6430\n",
      "6431\n",
      "6432\n",
      "6433\n",
      "6434\n",
      "6435\n",
      "6436\n",
      "6437\n",
      "6438\n",
      "6439\n",
      "6440\n",
      "6441\n",
      "6442\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6446\n",
      "6447\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6455\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6460\n",
      "6461\n",
      "6462\n",
      "6463\n",
      "6464\n",
      "6465\n",
      "6466\n",
      "6467\n",
      "6468\n",
      "6469\n",
      "6470\n",
      "6471\n",
      "6472\n",
      "6473\n",
      "6474\n",
      "6475\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6481\n",
      "6482\n",
      "6483\n",
      "6484\n",
      "6485\n",
      "6486\n",
      "6487\n",
      "6488\n",
      "6489\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6493\n",
      "6494\n",
      "6495\n",
      "6496\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6506\n",
      "6507\n",
      "6508\n",
      "6509\n",
      "6510\n",
      "6511\n",
      "6512\n",
      "6513\n",
      "6514\n",
      "6515\n",
      "6516\n",
      "6517\n",
      "6518\n",
      "6519\n",
      "6520\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6524\n",
      "6525\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6537\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6547\n",
      "6548\n",
      "6549\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6555\n",
      "6556\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6562\n",
      "6563\n",
      "6564\n",
      "6565\n",
      "6566\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6572\n",
      "6573\n",
      "6574\n",
      "6575\n",
      "6576\n",
      "6577\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6582\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6588\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6607\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6631\n",
      "6632\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6647\n",
      "6648\n",
      "6649\n",
      "6650\n",
      "6651\n",
      "6652\n",
      "6653\n",
      "6654\n",
      "6655\n",
      "6656\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6666\n",
      "6667\n",
      "6668\n",
      "6669\n",
      "6670\n",
      "6671\n",
      "6672\n",
      "6673\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6678\n",
      "6679\n",
      "6680\n",
      "6681\n",
      "6682\n",
      "6683\n",
      "6684\n",
      "6685\n",
      "6686\n",
      "6687\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6693\n",
      "6694\n",
      "6695\n",
      "6696\n",
      "6697\n",
      "6698\n",
      "6699\n",
      "6700\n",
      "6701\n",
      "6702\n",
      "6703\n",
      "6704\n",
      "6705\n",
      "6706\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6710\n",
      "6711\n",
      "6712\n",
      "6713\n",
      "6714\n",
      "6715\n",
      "6716\n",
      "6717\n",
      "6718\n",
      "6719\n",
      "6720\n",
      "6721\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6725\n",
      "6726\n",
      "6727\n",
      "6728\n",
      "6729\n",
      "6730\n",
      "6731\n",
      "6732\n",
      "6733\n",
      "6734\n",
      "6735\n",
      "6736\n",
      "6737\n",
      "6738\n",
      "6739\n",
      "6740\n",
      "6741\n",
      "6742\n",
      "6743\n",
      "6744\n",
      "6745\n",
      "6746\n",
      "6747\n",
      "6748\n",
      "6749\n",
      "6750\n",
      "6751\n",
      "6752\n",
      "6753\n",
      "6754\n",
      "6755\n",
      "6756\n",
      "6757\n",
      "6758\n",
      "6759\n",
      "6760\n",
      "6761\n",
      "6762\n",
      "6763\n",
      "6764\n",
      "6765\n",
      "6766\n",
      "6767\n",
      "6768\n",
      "6769\n",
      "6770\n",
      "6771\n",
      "6772\n",
      "6773\n",
      "6774\n",
      "6775\n",
      "6776\n",
      "6777\n",
      "6778\n",
      "6779\n",
      "6780\n",
      "6781\n",
      "6782\n",
      "6783\n",
      "6784\n",
      "6785\n",
      "6786\n",
      "6787\n",
      "6788\n",
      "6789\n",
      "6790\n",
      "6791\n",
      "6792\n",
      "6793\n",
      "6794\n",
      "6795\n",
      "6796\n",
      "6797\n",
      "6798\n",
      "6799\n",
      "6800\n",
      "6801\n",
      "6802\n",
      "6803\n",
      "6804\n",
      "6805\n",
      "6806\n",
      "6807\n",
      "6808\n",
      "6809\n",
      "6810\n",
      "6811\n",
      "6812\n",
      "6813\n",
      "6814\n",
      "6815\n",
      "6816\n",
      "6817\n",
      "6818\n",
      "6819\n",
      "6820\n",
      "6821\n",
      "6822\n",
      "6823\n",
      "6824\n",
      "6825\n",
      "6826\n",
      "6827\n",
      "6828\n",
      "6829\n",
      "6830\n",
      "6831\n",
      "6832\n",
      "6833\n",
      "6834\n",
      "6835\n",
      "6836\n",
      "6837\n",
      "6838\n",
      "6839\n",
      "6840\n",
      "6841\n",
      "6842\n",
      "6843\n",
      "6844\n",
      "6845\n",
      "6846\n",
      "6847\n",
      "6848\n",
      "6849\n",
      "6850\n",
      "6851\n",
      "6852\n",
      "6853\n",
      "6854\n",
      "6855\n",
      "6856\n",
      "6857\n",
      "6858\n",
      "6859\n",
      "6860\n",
      "6861\n",
      "6862\n",
      "6863\n",
      "6864\n",
      "6865\n",
      "6866\n",
      "6867\n",
      "6868\n",
      "6869\n",
      "6870\n",
      "6871\n",
      "6872\n",
      "6873\n",
      "6874\n",
      "6875\n",
      "6876\n",
      "6877\n",
      "6878\n",
      "6879\n",
      "6880\n",
      "6881\n",
      "6882\n",
      "6883\n",
      "6884\n",
      "6885\n",
      "6886\n",
      "6887\n",
      "6888\n",
      "6889\n",
      "6890\n",
      "6891\n",
      "6892\n",
      "6893\n",
      "6894\n",
      "6895\n",
      "6896\n",
      "6897\n",
      "6898\n",
      "6899\n",
      "6900\n",
      "6901\n",
      "6902\n",
      "6903\n",
      "6904\n",
      "6905\n",
      "6906\n",
      "6907\n",
      "6908\n",
      "6909\n",
      "6910\n",
      "6911\n",
      "6912\n",
      "6913\n",
      "6914\n",
      "6915\n",
      "6916\n",
      "6917\n",
      "6918\n",
      "6919\n",
      "6920\n",
      "6921\n",
      "6922\n",
      "6923\n",
      "6924\n",
      "6925\n",
      "6926\n",
      "6927\n",
      "6928\n",
      "6929\n",
      "6930\n",
      "6931\n",
      "6932\n",
      "6933\n",
      "6934\n",
      "6935\n",
      "6936\n",
      "6937\n",
      "6938\n",
      "6939\n",
      "6940\n",
      "6941\n",
      "6942\n",
      "6943\n",
      "6944\n",
      "6945\n",
      "6946\n",
      "6947\n",
      "6948\n",
      "6949\n",
      "6950\n",
      "6951\n",
      "6952\n",
      "6953\n",
      "6954\n",
      "6955\n",
      "6956\n",
      "6957\n",
      "6958\n",
      "6959\n",
      "6960\n",
      "6961\n",
      "6962\n",
      "6963\n",
      "6964\n",
      "6965\n",
      "6966\n",
      "6967\n",
      "6968\n",
      "6969\n",
      "6970\n",
      "6971\n",
      "6972\n",
      "6973\n",
      "6974\n",
      "6975\n",
      "6976\n",
      "6977\n",
      "6978\n",
      "6979\n",
      "6980\n",
      "6981\n",
      "6982\n",
      "6983\n",
      "6984\n",
      "6985\n",
      "6986\n",
      "6987\n",
      "6988\n",
      "6989\n",
      "6990\n",
      "6991\n",
      "6992\n",
      "6993\n",
      "6994\n",
      "6995\n",
      "6996\n",
      "6997\n",
      "6998\n",
      "6999\n",
      "7000\n",
      "7001\n",
      "7002\n",
      "7003\n",
      "7004\n",
      "7005\n",
      "7006\n",
      "7007\n",
      "7008\n",
      "7009\n",
      "7010\n",
      "7011\n",
      "7012\n",
      "7013\n",
      "7014\n",
      "7015\n",
      "7016\n",
      "7017\n",
      "7018\n",
      "7019\n",
      "7020\n",
      "7021\n",
      "7022\n",
      "7023\n",
      "7024\n",
      "7025\n",
      "7026\n",
      "7027\n",
      "7028\n",
      "7029\n",
      "7030\n",
      "7031\n",
      "7032\n",
      "7033\n",
      "7034\n",
      "7035\n",
      "7036\n",
      "7037\n",
      "7038\n",
      "7039\n",
      "7040\n",
      "7041\n",
      "7042\n",
      "7043\n",
      "7044\n",
      "7045\n",
      "7046\n",
      "7047\n",
      "7048\n",
      "7049\n",
      "7050\n",
      "7051\n",
      "7052\n",
      "7053\n",
      "7054\n",
      "7055\n",
      "7056\n",
      "7057\n",
      "7058\n",
      "7059\n",
      "7060\n",
      "7061\n",
      "7062\n",
      "7063\n",
      "7064\n",
      "7065\n",
      "7066\n",
      "7067\n",
      "7068\n",
      "7069\n",
      "7070\n",
      "7071\n",
      "7072\n",
      "7073\n",
      "7074\n",
      "7075\n",
      "7076\n",
      "7077\n",
      "7078\n",
      "7079\n",
      "7080\n",
      "7081\n",
      "7082\n",
      "7083\n",
      "7084\n",
      "7085\n",
      "7086\n",
      "7087\n",
      "7088\n",
      "7089\n",
      "7090\n",
      "7091\n",
      "7092\n",
      "7093\n",
      "7094\n",
      "7095\n",
      "7096\n",
      "7097\n",
      "7098\n",
      "7099\n",
      "7100\n",
      "7101\n",
      "7102\n",
      "7103\n",
      "7104\n",
      "7105\n",
      "7106\n",
      "7107\n",
      "7108\n",
      "7109\n",
      "7110\n",
      "7111\n",
      "7112\n",
      "7113\n",
      "7114\n",
      "7115\n",
      "7116\n",
      "7117\n",
      "7118\n",
      "7119\n",
      "7120\n",
      "7121\n",
      "7122\n",
      "7123\n",
      "7124\n",
      "7125\n",
      "7126\n",
      "7127\n",
      "7128\n",
      "7129\n",
      "7130\n",
      "7131\n",
      "7132\n",
      "7133\n",
      "7134\n",
      "7135\n",
      "7136\n",
      "7137\n",
      "7138\n",
      "7139\n",
      "7140\n",
      "7141\n",
      "7142\n",
      "7143\n",
      "7144\n",
      "7145\n",
      "7146\n",
      "7147\n",
      "7148\n",
      "7149\n",
      "7150\n",
      "7151\n",
      "7152\n",
      "7153\n",
      "7154\n",
      "7155\n",
      "7156\n",
      "7157\n",
      "7158\n",
      "7159\n",
      "7160\n",
      "7161\n",
      "7162\n",
      "7163\n",
      "7164\n",
      "7165\n",
      "7166\n",
      "7167\n",
      "7168\n",
      "7169\n",
      "7170\n",
      "7171\n",
      "7172\n",
      "7173\n",
      "7174\n",
      "7175\n",
      "7176\n",
      "7177\n",
      "7178\n",
      "7179\n",
      "7180\n",
      "7181\n",
      "7182\n",
      "7183\n",
      "7184\n",
      "7185\n",
      "7186\n",
      "7187\n",
      "7188\n",
      "7189\n",
      "7190\n",
      "7191\n",
      "7192\n",
      "7193\n",
      "7194\n",
      "7195\n",
      "7196\n",
      "7197\n",
      "7198\n",
      "7199\n",
      "7200\n",
      "7201\n",
      "7202\n",
      "7203\n",
      "7204\n",
      "7205\n",
      "7206\n",
      "7207\n",
      "7208\n",
      "7209\n",
      "7210\n",
      "7211\n",
      "7212\n",
      "7213\n",
      "7214\n",
      "7215\n",
      "7216\n",
      "7217\n",
      "7218\n",
      "7219\n",
      "7220\n",
      "7221\n",
      "7222\n",
      "7223\n",
      "7224\n",
      "7225\n",
      "7226\n",
      "7227\n",
      "7228\n",
      "7229\n",
      "7230\n",
      "7231\n",
      "7232\n",
      "7233\n",
      "7234\n",
      "7235\n",
      "7236\n",
      "7237\n",
      "7238\n",
      "7239\n",
      "7240\n",
      "7241\n",
      "7242\n",
      "7243\n",
      "7244\n",
      "7245\n",
      "7246\n",
      "7247\n",
      "7248\n",
      "7249\n",
      "7250\n",
      "7251\n",
      "7252\n",
      "7253\n",
      "7254\n",
      "7255\n",
      "7256\n",
      "7257\n",
      "7258\n",
      "7259\n",
      "7260\n",
      "7261\n",
      "7262\n",
      "7263\n",
      "7264\n",
      "7265\n",
      "7266\n",
      "7267\n",
      "7268\n",
      "7269\n",
      "7270\n",
      "7271\n",
      "7272\n",
      "7273\n",
      "7274\n",
      "7275\n",
      "7276\n",
      "7277\n",
      "7278\n",
      "7279\n",
      "7280\n",
      "7281\n",
      "7282\n",
      "7283\n",
      "7284\n",
      "7285\n",
      "7286\n",
      "7287\n",
      "7288\n",
      "7289\n",
      "7290\n",
      "7291\n",
      "7292\n",
      "7293\n",
      "7294\n",
      "7295\n",
      "7296\n",
      "7297\n",
      "7298\n",
      "7299\n",
      "7300\n",
      "7301\n",
      "7302\n",
      "7303\n",
      "7304\n",
      "7305\n",
      "7306\n",
      "7307\n",
      "7308\n",
      "7309\n",
      "7310\n",
      "7311\n",
      "7312\n",
      "7313\n",
      "7314\n",
      "7315\n",
      "7316\n",
      "7317\n",
      "7318\n",
      "7319\n",
      "7320\n",
      "7321\n",
      "7322\n",
      "7323\n",
      "7324\n",
      "7325\n",
      "7326\n",
      "7327\n",
      "7328\n",
      "7329\n",
      "7330\n",
      "7331\n",
      "7332\n",
      "7333\n",
      "7334\n",
      "7335\n",
      "7336\n",
      "7337\n",
      "7338\n",
      "7339\n",
      "7340\n",
      "7341\n",
      "7342\n",
      "7343\n",
      "7344\n",
      "7345\n",
      "7346\n",
      "7347\n",
      "7348\n",
      "7349\n",
      "7350\n",
      "7351\n",
      "7352\n",
      "7353\n",
      "7354\n",
      "7355\n",
      "7356\n",
      "7357\n",
      "7358\n",
      "7359\n",
      "7360\n",
      "7361\n",
      "7362\n",
      "7363\n",
      "7364\n",
      "7365\n",
      "7366\n",
      "7367\n",
      "7368\n",
      "7369\n",
      "7370\n",
      "7371\n",
      "7372\n",
      "7373\n",
      "7374\n",
      "7375\n",
      "7376\n",
      "7377\n",
      "7378\n",
      "7379\n",
      "7380\n",
      "7381\n",
      "7382\n",
      "7383\n",
      "7384\n",
      "7385\n",
      "7386\n",
      "7387\n",
      "7388\n",
      "7389\n",
      "7390\n",
      "7391\n",
      "7392\n",
      "7393\n",
      "7394\n",
      "7395\n",
      "7396\n",
      "7397\n",
      "7398\n",
      "7399\n",
      "7400\n",
      "7401\n",
      "7402\n",
      "7403\n",
      "7404\n",
      "7405\n",
      "7406\n",
      "7407\n",
      "7408\n",
      "7409\n",
      "7410\n",
      "7411\n",
      "7412\n",
      "7413\n",
      "7414\n",
      "7415\n",
      "7416\n",
      "7417\n",
      "7418\n",
      "7419\n",
      "7420\n",
      "7421\n",
      "7422\n",
      "7423\n",
      "7424\n",
      "7425\n",
      "7426\n",
      "7427\n",
      "7428\n",
      "7429\n",
      "7430\n",
      "7431\n",
      "7432\n",
      "7433\n",
      "7434\n",
      "7435\n",
      "7436\n",
      "7437\n",
      "7438\n",
      "7439\n",
      "7440\n",
      "7441\n",
      "7442\n",
      "7443\n",
      "7444\n",
      "7445\n",
      "7446\n",
      "7447\n",
      "7448\n",
      "7449\n",
      "7450\n",
      "7451\n",
      "7452\n",
      "7453\n",
      "7454\n",
      "7455\n",
      "7456\n",
      "7457\n",
      "7458\n",
      "7459\n",
      "7460\n",
      "7461\n",
      "7462\n",
      "7463\n",
      "7464\n",
      "7465\n",
      "7466\n",
      "7467\n",
      "7468\n",
      "7469\n",
      "7470\n",
      "7471\n",
      "7472\n",
      "7473\n",
      "7474\n",
      "7475\n",
      "7476\n",
      "7477\n",
      "7478\n",
      "7479\n",
      "7480\n",
      "7481\n",
      "7482\n",
      "7483\n",
      "7484\n",
      "7485\n",
      "7486\n",
      "7487\n",
      "7488\n",
      "7489\n",
      "7490\n",
      "7491\n",
      "7492\n",
      "7493\n",
      "7494\n",
      "7495\n",
      "7496\n",
      "7497\n",
      "7498\n",
      "7499\n",
      "7500\n",
      "7501\n",
      "7502\n",
      "7503\n",
      "7504\n",
      "7505\n",
      "7506\n",
      "7507\n",
      "7508\n",
      "7509\n",
      "7510\n",
      "7511\n",
      "7512\n",
      "7513\n",
      "7514\n",
      "7515\n",
      "7516\n",
      "7517\n",
      "7518\n",
      "7519\n",
      "7520\n",
      "7521\n",
      "7522\n",
      "7523\n",
      "7524\n",
      "7525\n",
      "7526\n",
      "7527\n",
      "7528\n",
      "7529\n",
      "7530\n",
      "7531\n",
      "7532\n",
      "7533\n",
      "7534\n",
      "7535\n",
      "7536\n",
      "7537\n",
      "7538\n",
      "7539\n",
      "7540\n",
      "7541\n",
      "7542\n",
      "7543\n",
      "7544\n",
      "7545\n",
      "7546\n",
      "7547\n",
      "7548\n",
      "7549\n",
      "7550\n",
      "7551\n",
      "7552\n",
      "7553\n",
      "7554\n",
      "7555\n",
      "7556\n",
      "7557\n",
      "7558\n",
      "7559\n",
      "7560\n",
      "7561\n",
      "7562\n",
      "7563\n",
      "7564\n",
      "7565\n",
      "7566\n",
      "7567\n",
      "7568\n",
      "7569\n",
      "7570\n",
      "7571\n",
      "7572\n",
      "7573\n",
      "7574\n",
      "7575\n",
      "7576\n",
      "7577\n",
      "7578\n",
      "7579\n",
      "7580\n",
      "7581\n",
      "7582\n",
      "7583\n",
      "7584\n",
      "7585\n",
      "7586\n",
      "7587\n",
      "7588\n",
      "7589\n",
      "7590\n",
      "7591\n",
      "7592\n",
      "7593\n",
      "7594\n",
      "7595\n",
      "7596\n",
      "7597\n",
      "7598\n",
      "7599\n",
      "7600\n",
      "7601\n",
      "7602\n",
      "7603\n",
      "7604\n",
      "7605\n",
      "7606\n",
      "7607\n",
      "7608\n",
      "7609\n",
      "7610\n",
      "7611\n",
      "7612\n",
      "7613\n",
      "7614\n",
      "7615\n",
      "7616\n",
      "7617\n",
      "7618\n",
      "7619\n",
      "7620\n",
      "7621\n",
      "7622\n",
      "7623\n",
      "7624\n",
      "7625\n",
      "7626\n",
      "7627\n",
      "7628\n",
      "7629\n",
      "7630\n",
      "7631\n",
      "7632\n",
      "7633\n",
      "7634\n",
      "7635\n",
      "7636\n",
      "7637\n",
      "7638\n",
      "7639\n",
      "7640\n",
      "7641\n",
      "7642\n",
      "7643\n",
      "7644\n",
      "7645\n",
      "7646\n",
      "7647\n",
      "7648\n",
      "7649\n",
      "7650\n",
      "7651\n",
      "7652\n",
      "7653\n",
      "7654\n",
      "7655\n",
      "7656\n",
      "7657\n",
      "7658\n",
      "7659\n",
      "7660\n",
      "7661\n",
      "7662\n",
      "7663\n",
      "7664\n",
      "7665\n",
      "7666\n",
      "7667\n",
      "7668\n",
      "7669\n",
      "7670\n",
      "7671\n",
      "7672\n",
      "7673\n",
      "7674\n",
      "7675\n",
      "7676\n",
      "7677\n",
      "7678\n",
      "7679\n",
      "7680\n",
      "7681\n",
      "7682\n",
      "7683\n",
      "7684\n",
      "7685\n",
      "7686\n",
      "7687\n",
      "7688\n",
      "7689\n",
      "7690\n",
      "7691\n",
      "7692\n",
      "7693\n",
      "7694\n",
      "7695\n",
      "7696\n",
      "7697\n",
      "7698\n",
      "7699\n",
      "7700\n",
      "7701\n",
      "7702\n",
      "7703\n",
      "7704\n",
      "7705\n",
      "7706\n",
      "7707\n",
      "7708\n",
      "7709\n",
      "7710\n",
      "7711\n",
      "7712\n",
      "7713\n",
      "7714\n",
      "7715\n",
      "7716\n",
      "7717\n",
      "7718\n",
      "7719\n",
      "7720\n",
      "7721\n",
      "7722\n",
      "7723\n",
      "7724\n",
      "7725\n",
      "7726\n",
      "7727\n",
      "7728\n",
      "7729\n",
      "7730\n",
      "7731\n",
      "7732\n",
      "7733\n",
      "7734\n",
      "7735\n",
      "7736\n",
      "7737\n",
      "7738\n",
      "7739\n",
      "7740\n",
      "7741\n",
      "7742\n",
      "7743\n",
      "7744\n",
      "7745\n",
      "7746\n",
      "7747\n",
      "7748\n",
      "7749\n",
      "7750\n",
      "7751\n",
      "7752\n",
      "7753\n",
      "7754\n",
      "7755\n",
      "7756\n",
      "7757\n",
      "7758\n",
      "7759\n",
      "7760\n",
      "7761\n",
      "7762\n",
      "7763\n",
      "7764\n",
      "7765\n",
      "7766\n",
      "7767\n",
      "7768\n",
      "7769\n",
      "7770\n",
      "7771\n",
      "7772\n",
      "7773\n",
      "7774\n",
      "7775\n",
      "7776\n",
      "7777\n",
      "7778\n",
      "7779\n",
      "7780\n",
      "7781\n",
      "7782\n",
      "7783\n",
      "7784\n",
      "7785\n",
      "7786\n",
      "7787\n",
      "7788\n",
      "7789\n",
      "7790\n",
      "7791\n",
      "7792\n",
      "7793\n",
      "7794\n",
      "7795\n",
      "7796\n",
      "7797\n",
      "7798\n",
      "7799\n",
      "7800\n",
      "7801\n",
      "7802\n",
      "7803\n",
      "7804\n",
      "7805\n",
      "7806\n",
      "7807\n",
      "7808\n",
      "7809\n",
      "7810\n",
      "7811\n",
      "7812\n",
      "7813\n",
      "7814\n",
      "7815\n",
      "7816\n",
      "7817\n",
      "7818\n",
      "7819\n",
      "7820\n",
      "7821\n",
      "7822\n",
      "7823\n",
      "7824\n",
      "7825\n",
      "7826\n",
      "7827\n",
      "7828\n",
      "7829\n",
      "7830\n",
      "7831\n",
      "7832\n",
      "7833\n",
      "7834\n",
      "7835\n",
      "7836\n",
      "7837\n",
      "7838\n",
      "7839\n",
      "7840\n",
      "7841\n",
      "7842\n",
      "7843\n",
      "7844\n",
      "7845\n",
      "7846\n",
      "7847\n",
      "7848\n",
      "7849\n",
      "7850\n",
      "7851\n",
      "7852\n",
      "7853\n",
      "7854\n",
      "7855\n",
      "7856\n",
      "7857\n",
      "7858\n",
      "7859\n",
      "7860\n",
      "7861\n",
      "7862\n",
      "7863\n",
      "7864\n",
      "7865\n",
      "7866\n",
      "7867\n",
      "7868\n",
      "7869\n",
      "7870\n",
      "7871\n",
      "7872\n",
      "7873\n",
      "7874\n",
      "7875\n",
      "7876\n",
      "7877\n",
      "7878\n",
      "7879\n",
      "7880\n",
      "7881\n",
      "7882\n",
      "7883\n",
      "7884\n",
      "7885\n",
      "7886\n",
      "7887\n",
      "7888\n",
      "7889\n",
      "7890\n",
      "7891\n",
      "7892\n",
      "7893\n",
      "7894\n",
      "7895\n",
      "7896\n",
      "7897\n",
      "7898\n",
      "7899\n",
      "7900\n",
      "7901\n",
      "7902\n",
      "7903\n",
      "7904\n",
      "7905\n",
      "7906\n",
      "7907\n",
      "7908\n",
      "7909\n",
      "7910\n",
      "7911\n",
      "7912\n",
      "7913\n",
      "7914\n",
      "7915\n",
      "7916\n",
      "7917\n",
      "7918\n",
      "7919\n",
      "7920\n",
      "7921\n",
      "7922\n",
      "7923\n",
      "7924\n",
      "7925\n",
      "7926\n",
      "7927\n",
      "7928\n",
      "7929\n",
      "7930\n",
      "7931\n",
      "7932\n",
      "7933\n",
      "7934\n",
      "7935\n",
      "7936\n",
      "7937\n",
      "7938\n",
      "7939\n",
      "7940\n",
      "7941\n",
      "7942\n",
      "7943\n",
      "7944\n",
      "7945\n",
      "7946\n",
      "7947\n",
      "7948\n",
      "7949\n",
      "7950\n",
      "7951\n",
      "7952\n",
      "7953\n",
      "7954\n",
      "7955\n",
      "7956\n",
      "7957\n",
      "7958\n",
      "7959\n",
      "7960\n",
      "7961\n",
      "7962\n",
      "7963\n",
      "7964\n",
      "7965\n",
      "7966\n",
      "7967\n",
      "7968\n",
      "7969\n",
      "7970\n",
      "7971\n",
      "7972\n",
      "7973\n",
      "7974\n",
      "7975\n",
      "7976\n",
      "7977\n",
      "7978\n",
      "7979\n",
      "7980\n",
      "7981\n",
      "7982\n",
      "7983\n",
      "7984\n",
      "7985\n",
      "7986\n",
      "7987\n",
      "7988\n",
      "7989\n",
      "7990\n",
      "7991\n",
      "7992\n",
      "7993\n",
      "7994\n",
      "7995\n",
      "7996\n",
      "7997\n",
      "7998\n",
      "7999\n",
      "8000\n",
      "8001\n",
      "8002\n",
      "8003\n",
      "8004\n",
      "8005\n",
      "8006\n",
      "8007\n",
      "8008\n",
      "8009\n",
      "8010\n",
      "8011\n",
      "8012\n",
      "8013\n",
      "8014\n",
      "8015\n",
      "8016\n",
      "8017\n",
      "8018\n",
      "8019\n",
      "8020\n",
      "8021\n",
      "8022\n",
      "8023\n",
      "8024\n",
      "8025\n",
      "8026\n",
      "8027\n",
      "8028\n",
      "8029\n",
      "8030\n",
      "8031\n",
      "8032\n",
      "8033\n",
      "8034\n",
      "8035\n",
      "8036\n",
      "8037\n",
      "8038\n",
      "8039\n",
      "8040\n",
      "8041\n",
      "8042\n",
      "8043\n",
      "8044\n",
      "8045\n",
      "8046\n",
      "8047\n",
      "8048\n",
      "8049\n",
      "8050\n",
      "8051\n",
      "8052\n",
      "8053\n",
      "8054\n",
      "8055\n",
      "8056\n",
      "8057\n",
      "8058\n",
      "8059\n",
      "8060\n",
      "8061\n",
      "8062\n",
      "8063\n",
      "8064\n",
      "8065\n",
      "8066\n",
      "8067\n",
      "8068\n",
      "8069\n",
      "8070\n",
      "8071\n",
      "8072\n",
      "8073\n",
      "8074\n",
      "8075\n",
      "8076\n",
      "8077\n",
      "8078\n",
      "8079\n",
      "8080\n",
      "8081\n",
      "8082\n",
      "8083\n",
      "8084\n",
      "8085\n",
      "8086\n",
      "8087\n",
      "8088\n",
      "8089\n",
      "8090\n",
      "8091\n",
      "8092\n",
      "8093\n",
      "8094\n",
      "8095\n",
      "8096\n",
      "8097\n",
      "8098\n",
      "8099\n",
      "8100\n",
      "8101\n",
      "8102\n",
      "8103\n",
      "8104\n",
      "8105\n",
      "8106\n",
      "8107\n",
      "8108\n",
      "8109\n",
      "8110\n",
      "8111\n",
      "8112\n",
      "8113\n",
      "8114\n",
      "8115\n",
      "8116\n",
      "8117\n",
      "8118\n",
      "8119\n",
      "8120\n",
      "8121\n",
      "8122\n",
      "8123\n",
      "8124\n",
      "8125\n",
      "8126\n",
      "8127\n",
      "8128\n",
      "8129\n",
      "8130\n",
      "8131\n",
      "8132\n",
      "8133\n",
      "8134\n",
      "8135\n",
      "8136\n",
      "8137\n",
      "8138\n",
      "8139\n",
      "8140\n",
      "8141\n",
      "8142\n",
      "8143\n",
      "8144\n",
      "8145\n",
      "8146\n",
      "8147\n",
      "8148\n",
      "8149\n",
      "8150\n",
      "8151\n",
      "8152\n",
      "8153\n",
      "8154\n",
      "8155\n",
      "8156\n",
      "8157\n",
      "8158\n",
      "8159\n",
      "8160\n",
      "8161\n",
      "8162\n",
      "8163\n",
      "8164\n",
      "8165\n",
      "8166\n",
      "8167\n",
      "8168\n",
      "8169\n",
      "8170\n",
      "8171\n",
      "8172\n",
      "8173\n",
      "8174\n",
      "8175\n",
      "8176\n",
      "8177\n",
      "8178\n",
      "8179\n",
      "8180\n",
      "8181\n",
      "8182\n",
      "8183\n",
      "8184\n",
      "8185\n",
      "8186\n",
      "8187\n",
      "8188\n",
      "8189\n",
      "8190\n",
      "8191\n",
      "8192\n",
      "8193\n",
      "8194\n",
      "8195\n",
      "8196\n",
      "8197\n",
      "8198\n",
      "8199\n",
      "8200\n",
      "8201\n",
      "8202\n",
      "8203\n",
      "8204\n",
      "8205\n",
      "8206\n",
      "8207\n",
      "8208\n",
      "8209\n",
      "8210\n",
      "8211\n",
      "8212\n",
      "8213\n",
      "8214\n",
      "8215\n",
      "8216\n",
      "8217\n",
      "8218\n",
      "8219\n",
      "8220\n",
      "8221\n",
      "8222\n",
      "8223\n",
      "8224\n",
      "8225\n",
      "8226\n",
      "8227\n",
      "8228\n",
      "8229\n",
      "8230\n",
      "8231\n",
      "8232\n",
      "8233\n",
      "8234\n",
      "8235\n",
      "8236\n",
      "8237\n",
      "8238\n",
      "8239\n",
      "8240\n",
      "8241\n",
      "8242\n",
      "8243\n",
      "8244\n",
      "8245\n",
      "8246\n",
      "8247\n",
      "8248\n",
      "8249\n",
      "8250\n",
      "8251\n",
      "8252\n",
      "8253\n",
      "8254\n",
      "8255\n",
      "8256\n",
      "8257\n",
      "8258\n",
      "8259\n",
      "8260\n",
      "8261\n",
      "8262\n",
      "8263\n",
      "8264\n",
      "8265\n",
      "8266\n",
      "8267\n",
      "8268\n",
      "8269\n",
      "8270\n",
      "8271\n",
      "8272\n",
      "8273\n",
      "8274\n",
      "8275\n",
      "8276\n",
      "8277\n",
      "8278\n",
      "8279\n",
      "8280\n",
      "8281\n",
      "8282\n",
      "8283\n",
      "8284\n",
      "8285\n",
      "8286\n",
      "8287\n",
      "8288\n",
      "8289\n",
      "8290\n",
      "8291\n",
      "8292\n",
      "8293\n",
      "8294\n",
      "8295\n",
      "8296\n",
      "8297\n",
      "8298\n",
      "8299\n",
      "8300\n",
      "8301\n",
      "8302\n",
      "8303\n",
      "8304\n",
      "8305\n",
      "8306\n",
      "8307\n",
      "8308\n",
      "8309\n",
      "8310\n",
      "8311\n",
      "8312\n",
      "8313\n",
      "8314\n",
      "8315\n",
      "8316\n",
      "8317\n",
      "8318\n",
      "8319\n",
      "8320\n",
      "8321\n",
      "8322\n",
      "8323\n",
      "8324\n",
      "8325\n",
      "8326\n",
      "8327\n",
      "8328\n",
      "8329\n",
      "8330\n",
      "8331\n",
      "8332\n",
      "8333\n",
      "8334\n",
      "8335\n",
      "8336\n",
      "8337\n",
      "8338\n",
      "8339\n",
      "8340\n",
      "8341\n",
      "8342\n",
      "8343\n",
      "8344\n",
      "8345\n",
      "8346\n",
      "8347\n",
      "8348\n",
      "8349\n",
      "8350\n",
      "8351\n",
      "8352\n",
      "8353\n",
      "8354\n",
      "8355\n",
      "8356\n",
      "8357\n",
      "8358\n",
      "8359\n",
      "8360\n",
      "8361\n",
      "8362\n",
      "8363\n",
      "8364\n",
      "8365\n",
      "8366\n",
      "8367\n",
      "8368\n",
      "8369\n",
      "8370\n",
      "8371\n",
      "8372\n",
      "8373\n",
      "8374\n",
      "8375\n",
      "8376\n",
      "8377\n",
      "8378\n",
      "8379\n",
      "8380\n",
      "8381\n",
      "8382\n",
      "8383\n",
      "8384\n",
      "8385\n",
      "8386\n",
      "8387\n",
      "8388\n",
      "8389\n",
      "8390\n",
      "8391\n",
      "8392\n",
      "8393\n",
      "8394\n",
      "8395\n",
      "8396\n",
      "8397\n",
      "8398\n",
      "8399\n",
      "8400\n",
      "8401\n",
      "8402\n",
      "8403\n",
      "8404\n",
      "8405\n",
      "8406\n",
      "8407\n",
      "8408\n",
      "8409\n",
      "8410\n",
      "8411\n",
      "8412\n",
      "8413\n",
      "8414\n",
      "8415\n",
      "8416\n",
      "8417\n",
      "8418\n",
      "8419\n",
      "8420\n",
      "8421\n",
      "8422\n",
      "8423\n",
      "8424\n",
      "8425\n",
      "8426\n",
      "8427\n",
      "8428\n",
      "8429\n",
      "8430\n",
      "8431\n",
      "8432\n",
      "8433\n",
      "8434\n",
      "8435\n",
      "8436\n",
      "8437\n",
      "8438\n",
      "8439\n",
      "8440\n",
      "8441\n",
      "8442\n",
      "8443\n",
      "8444\n",
      "8445\n",
      "8446\n",
      "8447\n",
      "8448\n",
      "8449\n",
      "8450\n",
      "8451\n",
      "8452\n",
      "8453\n",
      "8454\n",
      "8455\n",
      "8456\n",
      "8457\n",
      "8458\n",
      "8459\n",
      "8460\n",
      "8461\n",
      "8462\n",
      "8463\n",
      "8464\n",
      "8465\n",
      "8466\n",
      "8467\n",
      "8468\n",
      "8469\n",
      "8470\n",
      "8471\n",
      "8472\n",
      "8473\n",
      "8474\n",
      "8475\n",
      "8476\n",
      "8477\n",
      "8478\n",
      "8479\n",
      "8480\n",
      "8481\n",
      "8482\n",
      "8483\n",
      "8484\n",
      "8485\n",
      "8486\n",
      "8487\n",
      "8488\n",
      "8489\n",
      "8490\n",
      "8491\n",
      "8492\n",
      "8493\n",
      "8494\n",
      "8495\n",
      "8496\n",
      "8497\n",
      "8498\n",
      "8499\n",
      "8500\n",
      "8501\n",
      "8502\n",
      "8503\n",
      "8504\n",
      "8505\n",
      "8506\n",
      "8507\n",
      "8508\n",
      "8509\n",
      "8510\n",
      "8511\n",
      "8512\n",
      "8513\n",
      "8514\n",
      "8515\n",
      "8516\n",
      "8517\n",
      "8518\n",
      "8519\n",
      "8520\n",
      "8521\n",
      "8522\n",
      "8523\n",
      "8524\n",
      "8525\n",
      "8526\n",
      "8527\n",
      "8528\n",
      "8529\n",
      "8530\n",
      "8531\n",
      "8532\n",
      "8533\n",
      "8534\n",
      "8535\n",
      "8536\n",
      "8537\n",
      "8538\n",
      "8539\n",
      "8540\n",
      "8541\n",
      "8542\n",
      "8543\n",
      "8544\n",
      "8545\n",
      "8546\n",
      "8547\n",
      "8548\n",
      "8549\n",
      "8550\n",
      "8551\n",
      "8552\n",
      "8553\n",
      "8554\n",
      "8555\n",
      "8556\n",
      "8557\n",
      "8558\n",
      "8559\n",
      "8560\n",
      "8561\n",
      "8562\n",
      "8563\n",
      "8564\n",
      "8565\n",
      "8566\n",
      "8567\n",
      "8568\n",
      "8569\n",
      "8570\n",
      "8571\n",
      "8572\n",
      "8573\n",
      "8574\n",
      "8575\n",
      "8576\n",
      "8577\n",
      "8578\n",
      "8579\n",
      "8580\n",
      "8581\n",
      "8582\n",
      "8583\n",
      "8584\n",
      "8585\n",
      "8586\n",
      "8587\n",
      "8588\n",
      "8589\n",
      "8590\n",
      "8591\n",
      "8592\n",
      "8593\n",
      "8594\n",
      "8595\n",
      "8596\n",
      "8597\n",
      "8598\n",
      "8599\n",
      "8600\n",
      "8601\n",
      "8602\n",
      "8603\n",
      "8604\n",
      "8605\n",
      "8606\n",
      "8607\n",
      "8608\n",
      "8609\n",
      "8610\n",
      "8611\n",
      "8612\n",
      "8613\n",
      "8614\n",
      "8615\n",
      "8616\n",
      "8617\n",
      "8618\n",
      "8619\n",
      "8620\n",
      "8621\n",
      "8622\n",
      "8623\n",
      "8624\n",
      "8625\n",
      "8626\n",
      "8627\n",
      "8628\n",
      "8629\n",
      "8630\n",
      "8631\n",
      "8632\n",
      "8633\n",
      "8634\n",
      "8635\n",
      "8636\n",
      "8637\n",
      "8638\n",
      "8639\n",
      "8640\n",
      "8641\n",
      "8642\n",
      "8643\n",
      "8644\n",
      "8645\n",
      "8646\n",
      "8647\n",
      "8648\n",
      "8649\n",
      "8650\n",
      "8651\n",
      "8652\n",
      "8653\n",
      "8654\n",
      "8655\n",
      "8656\n",
      "8657\n",
      "8658\n",
      "8659\n",
      "8660\n",
      "8661\n",
      "8662\n",
      "8663\n",
      "8664\n",
      "8665\n",
      "8666\n",
      "8667\n",
      "8668\n",
      "8669\n",
      "8670\n",
      "8671\n",
      "8672\n",
      "8673\n",
      "8674\n",
      "8675\n",
      "8676\n",
      "8677\n",
      "8678\n",
      "8679\n",
      "8680\n",
      "8681\n",
      "8682\n",
      "8683\n",
      "8684\n",
      "8685\n",
      "8686\n",
      "8687\n",
      "8688\n",
      "8689\n",
      "8690\n",
      "8691\n",
      "8692\n",
      "8693\n",
      "8694\n",
      "8695\n",
      "8696\n",
      "8697\n",
      "8698\n",
      "8699\n",
      "8700\n",
      "8701\n",
      "8702\n",
      "8703\n",
      "8704\n",
      "8705\n",
      "8706\n",
      "8707\n",
      "8708\n",
      "8709\n",
      "8710\n",
      "8711\n",
      "8712\n",
      "8713\n",
      "8714\n",
      "8715\n",
      "8716\n",
      "8717\n",
      "8718\n",
      "8719\n",
      "8720\n",
      "8721\n",
      "8722\n",
      "8723\n",
      "8724\n",
      "8725\n",
      "8726\n",
      "8727\n",
      "8728\n",
      "8729\n",
      "8730\n",
      "8731\n",
      "8732\n",
      "8733\n",
      "8734\n",
      "8735\n",
      "8736\n",
      "8737\n",
      "8738\n",
      "8739\n",
      "8740\n",
      "8741\n",
      "8742\n",
      "8743\n",
      "8744\n",
      "8745\n",
      "8746\n",
      "8747\n",
      "8748\n",
      "8749\n",
      "8750\n",
      "8751\n",
      "8752\n",
      "8753\n",
      "8754\n",
      "8755\n",
      "8756\n",
      "8757\n",
      "8758\n",
      "8759\n",
      "8760\n",
      "8761\n",
      "8762\n",
      "8763\n",
      "8764\n",
      "8765\n",
      "8766\n",
      "8767\n",
      "8768\n",
      "8769\n",
      "8770\n",
      "8771\n",
      "8772\n",
      "8773\n",
      "8774\n",
      "8775\n",
      "8776\n",
      "8777\n",
      "8778\n",
      "8779\n",
      "8780\n",
      "8781\n",
      "8782\n",
      "8783\n",
      "8784\n",
      "8785\n",
      "8786\n",
      "8787\n",
      "8788\n",
      "8789\n",
      "8790\n",
      "8791\n",
      "8792\n",
      "8793\n",
      "8794\n",
      "8795\n",
      "8796\n",
      "8797\n",
      "8798\n",
      "8799\n",
      "8800\n",
      "8801\n",
      "8802\n",
      "8803\n",
      "8804\n",
      "8805\n",
      "8806\n",
      "8807\n",
      "8808\n",
      "8809\n",
      "8810\n",
      "8811\n",
      "8812\n",
      "8813\n",
      "8814\n",
      "8815\n",
      "8816\n",
      "8817\n",
      "8818\n",
      "8819\n",
      "8820\n",
      "8821\n",
      "8822\n",
      "8823\n",
      "8824\n",
      "8825\n",
      "8826\n",
      "8827\n",
      "8828\n",
      "8829\n",
      "8830\n",
      "8831\n",
      "8832\n",
      "8833\n",
      "8834\n",
      "8835\n",
      "8836\n",
      "8837\n",
      "8838\n",
      "8839\n",
      "8840\n",
      "8841\n",
      "8842\n",
      "8843\n",
      "8844\n",
      "8845\n",
      "8846\n",
      "8847\n",
      "8848\n",
      "8849\n",
      "8850\n",
      "8851\n",
      "8852\n",
      "8853\n",
      "8854\n",
      "8855\n",
      "8856\n",
      "8857\n",
      "8858\n",
      "8859\n",
      "8860\n",
      "8861\n",
      "8862\n",
      "8863\n",
      "8864\n",
      "8865\n",
      "8866\n",
      "8867\n",
      "8868\n",
      "8869\n",
      "8870\n",
      "8871\n",
      "8872\n",
      "8873\n",
      "8874\n",
      "8875\n",
      "8876\n",
      "8877\n",
      "8878\n",
      "8879\n",
      "8880\n",
      "8881\n",
      "8882\n",
      "8883\n",
      "8884\n",
      "8885\n",
      "8886\n",
      "8887\n",
      "8888\n",
      "8889\n",
      "8890\n",
      "8891\n",
      "8892\n",
      "8893\n",
      "8894\n",
      "8895\n",
      "8896\n",
      "8897\n",
      "8898\n",
      "8899\n",
      "8900\n",
      "8901\n",
      "8902\n",
      "8903\n",
      "8904\n",
      "8905\n",
      "8906\n",
      "8907\n",
      "8908\n",
      "8909\n",
      "8910\n",
      "8911\n",
      "8912\n",
      "8913\n",
      "8914\n",
      "8915\n",
      "8916\n",
      "8917\n",
      "8918\n",
      "8919\n",
      "8920\n",
      "8921\n",
      "8922\n",
      "8923\n",
      "8924\n",
      "8925\n",
      "8926\n",
      "8927\n",
      "8928\n",
      "8929\n",
      "8930\n",
      "8931\n",
      "8932\n",
      "8933\n",
      "8934\n",
      "8935\n",
      "8936\n",
      "8937\n",
      "8938\n",
      "8939\n",
      "8940\n",
      "8941\n",
      "8942\n",
      "8943\n",
      "8944\n",
      "8945\n",
      "8946\n",
      "8947\n",
      "8948\n",
      "8949\n",
      "8950\n",
      "8951\n",
      "8952\n",
      "8953\n",
      "8954\n",
      "8955\n",
      "8956\n",
      "8957\n",
      "8958\n",
      "8959\n",
      "8960\n",
      "8961\n",
      "8962\n",
      "8963\n",
      "8964\n",
      "8965\n",
      "8966\n",
      "8967\n",
      "8968\n",
      "8969\n",
      "8970\n",
      "8971\n",
      "8972\n",
      "8973\n",
      "8974\n",
      "8975\n",
      "8976\n",
      "8977\n",
      "8978\n",
      "8979\n",
      "8980\n",
      "8981\n",
      "8982\n",
      "8983\n",
      "8984\n",
      "8985\n",
      "8986\n",
      "8987\n",
      "8988\n",
      "8989\n",
      "8990\n",
      "8991\n",
      "8992\n",
      "8993\n",
      "8994\n",
      "8995\n",
      "8996\n",
      "8997\n",
      "8998\n",
      "8999\n",
      "9000\n",
      "9001\n",
      "9002\n",
      "9003\n",
      "9004\n",
      "9005\n",
      "9006\n",
      "9007\n",
      "9008\n",
      "9009\n",
      "9010\n",
      "9011\n",
      "9012\n",
      "9013\n",
      "9014\n",
      "9015\n",
      "9016\n",
      "9017\n",
      "9018\n",
      "9019\n",
      "9020\n",
      "9021\n",
      "9022\n",
      "9023\n",
      "9024\n",
      "9025\n",
      "9026\n",
      "9027\n",
      "9028\n",
      "9029\n",
      "9030\n",
      "9031\n",
      "9032\n",
      "9033\n",
      "9034\n",
      "9035\n",
      "9036\n",
      "9037\n",
      "9038\n",
      "9039\n",
      "9040\n",
      "9041\n",
      "9042\n",
      "9043\n",
      "9044\n",
      "9045\n",
      "9046\n",
      "9047\n",
      "9048\n",
      "9049\n",
      "9050\n",
      "9051\n",
      "9052\n",
      "9053\n",
      "9054\n",
      "9055\n",
      "9056\n",
      "9057\n",
      "9058\n",
      "9059\n",
      "9060\n",
      "9061\n",
      "9062\n",
      "9063\n",
      "9064\n",
      "9065\n",
      "9066\n",
      "9067\n",
      "9068\n",
      "9069\n",
      "9070\n",
      "9071\n",
      "9072\n",
      "9073\n",
      "9074\n",
      "9075\n",
      "9076\n",
      "9077\n",
      "9078\n",
      "9079\n",
      "9080\n",
      "9081\n",
      "9082\n",
      "9083\n",
      "9084\n",
      "9085\n",
      "9086\n",
      "9087\n",
      "9088\n",
      "9089\n",
      "9090\n",
      "9091\n",
      "9092\n",
      "9093\n",
      "9094\n",
      "9095\n",
      "9096\n",
      "9097\n",
      "9098\n",
      "9099\n",
      "9100\n",
      "9101\n",
      "9102\n",
      "9103\n",
      "9104\n",
      "9105\n",
      "9106\n",
      "9107\n",
      "9108\n",
      "9109\n",
      "9110\n",
      "9111\n",
      "9112\n",
      "9113\n",
      "9114\n",
      "9115\n",
      "9116\n",
      "9117\n",
      "9118\n",
      "9119\n",
      "9120\n",
      "9121\n",
      "9122\n",
      "9123\n",
      "9124\n",
      "9125\n",
      "9126\n",
      "9127\n",
      "9128\n",
      "9129\n",
      "9130\n",
      "9131\n",
      "9132\n",
      "9133\n",
      "9134\n",
      "9135\n",
      "9136\n",
      "9137\n",
      "9138\n",
      "9139\n",
      "9140\n",
      "9141\n",
      "9142\n",
      "9143\n",
      "9144\n",
      "9145\n",
      "9146\n",
      "9147\n",
      "9148\n",
      "9149\n",
      "9150\n",
      "9151\n",
      "9152\n",
      "9153\n",
      "9154\n",
      "9155\n",
      "9156\n",
      "9157\n",
      "9158\n",
      "9159\n",
      "9160\n",
      "9161\n",
      "9162\n",
      "9163\n",
      "9164\n",
      "9165\n",
      "9166\n",
      "9167\n",
      "9168\n",
      "9169\n",
      "9170\n",
      "9171\n",
      "9172\n",
      "9173\n",
      "9174\n",
      "9175\n",
      "9176\n",
      "9177\n",
      "9178\n",
      "9179\n",
      "9180\n",
      "9181\n",
      "9182\n",
      "9183\n",
      "9184\n",
      "9185\n",
      "9186\n",
      "9187\n",
      "9188\n",
      "9189\n",
      "9190\n",
      "9191\n",
      "9192\n",
      "9193\n",
      "9194\n",
      "9195\n",
      "9196\n",
      "9197\n",
      "9198\n",
      "9199\n",
      "9200\n",
      "9201\n",
      "9202\n",
      "9203\n",
      "9204\n",
      "9205\n",
      "9206\n",
      "9207\n",
      "9208\n",
      "9209\n",
      "9210\n",
      "9211\n",
      "9212\n",
      "9213\n",
      "9214\n",
      "9215\n",
      "9216\n",
      "9217\n",
      "9218\n",
      "9219\n",
      "9220\n",
      "9221\n",
      "9222\n",
      "9223\n",
      "9224\n",
      "9225\n",
      "9226\n",
      "9227\n",
      "9228\n",
      "9229\n",
      "9230\n",
      "9231\n",
      "9232\n",
      "9233\n",
      "9234\n",
      "9235\n",
      "9236\n",
      "9237\n",
      "9238\n",
      "9239\n",
      "9240\n",
      "9241\n",
      "9242\n",
      "9243\n",
      "9244\n",
      "9245\n",
      "9246\n",
      "9247\n",
      "9248\n",
      "9249\n",
      "9250\n",
      "9251\n",
      "9252\n",
      "9253\n",
      "9254\n",
      "9255\n",
      "9256\n",
      "9257\n",
      "9258\n",
      "9259\n",
      "9260\n",
      "9261\n",
      "9262\n",
      "9263\n",
      "9264\n",
      "9265\n",
      "9266\n",
      "9267\n",
      "9268\n",
      "9269\n",
      "9270\n",
      "9271\n",
      "9272\n",
      "9273\n",
      "9274\n",
      "9275\n",
      "9276\n",
      "9277\n",
      "9278\n",
      "9279\n",
      "9280\n",
      "9281\n",
      "9282\n",
      "9283\n",
      "9284\n",
      "9285\n",
      "9286\n",
      "9287\n",
      "9288\n",
      "9289\n",
      "9290\n",
      "9291\n",
      "9292\n",
      "9293\n",
      "9294\n",
      "9295\n",
      "9296\n",
      "9297\n",
      "9298\n",
      "9299\n",
      "9300\n",
      "9301\n",
      "9302\n",
      "9303\n",
      "9304\n",
      "9305\n",
      "9306\n",
      "9307\n",
      "9308\n",
      "9309\n",
      "9310\n",
      "9311\n",
      "9312\n",
      "9313\n",
      "9314\n",
      "9315\n",
      "9316\n",
      "9317\n",
      "9318\n",
      "9319\n",
      "9320\n",
      "9321\n",
      "9322\n",
      "9323\n",
      "9324\n",
      "9325\n",
      "9326\n",
      "9327\n",
      "9328\n",
      "9329\n",
      "9330\n",
      "9331\n",
      "9332\n",
      "9333\n",
      "9334\n",
      "9335\n",
      "9336\n",
      "9337\n",
      "9338\n",
      "9339\n",
      "9340\n",
      "9341\n",
      "9342\n",
      "9343\n",
      "9344\n",
      "9345\n",
      "9346\n",
      "9347\n",
      "9348\n",
      "9349\n",
      "9350\n",
      "9351\n",
      "9352\n",
      "9353\n",
      "9354\n",
      "9355\n",
      "9356\n",
      "9357\n",
      "9358\n",
      "9359\n",
      "9360\n",
      "9361\n",
      "9362\n",
      "9363\n",
      "9364\n",
      "9365\n",
      "9366\n",
      "9367\n",
      "9368\n",
      "9369\n",
      "9370\n",
      "9371\n",
      "9372\n",
      "9373\n",
      "9374\n",
      "9375\n",
      "9376\n",
      "9377\n",
      "9378\n",
      "9379\n",
      "9380\n",
      "9381\n",
      "9382\n",
      "9383\n",
      "9384\n",
      "9385\n",
      "9386\n",
      "9387\n",
      "9388\n",
      "9389\n",
      "9390\n",
      "9391\n",
      "9392\n",
      "9393\n",
      "9394\n",
      "9395\n",
      "9396\n",
      "9397\n",
      "9398\n",
      "9399\n",
      "9400\n",
      "9401\n",
      "9402\n",
      "9403\n",
      "9404\n",
      "9405\n",
      "9406\n",
      "9407\n",
      "9408\n",
      "9409\n",
      "9410\n",
      "9411\n",
      "9412\n",
      "9413\n",
      "9414\n",
      "9415\n",
      "9416\n",
      "9417\n",
      "9418\n",
      "9419\n",
      "9420\n",
      "9421\n",
      "9422\n",
      "9423\n",
      "9424\n",
      "9425\n",
      "9426\n",
      "9427\n",
      "9428\n",
      "9429\n",
      "9430\n",
      "9431\n",
      "9432\n",
      "9433\n",
      "9434\n",
      "9435\n",
      "9436\n",
      "9437\n",
      "9438\n",
      "9439\n",
      "9440\n",
      "9441\n",
      "9442\n",
      "9443\n",
      "9444\n",
      "9445\n",
      "9446\n",
      "9447\n",
      "9448\n",
      "9449\n",
      "9450\n",
      "9451\n",
      "9452\n",
      "9453\n",
      "9454\n",
      "9455\n",
      "9456\n",
      "9457\n",
      "9458\n",
      "9459\n",
      "9460\n",
      "9461\n",
      "9462\n",
      "9463\n",
      "9464\n",
      "9465\n",
      "9466\n",
      "9467\n",
      "9468\n",
      "9469\n",
      "9470\n",
      "9471\n",
      "9472\n",
      "9473\n",
      "9474\n",
      "9475\n",
      "9476\n",
      "9477\n",
      "9478\n",
      "9479\n",
      "9480\n",
      "9481\n",
      "9482\n",
      "9483\n",
      "9484\n",
      "9485\n",
      "9486\n",
      "9487\n",
      "9488\n",
      "9489\n",
      "9490\n",
      "9491\n",
      "9492\n",
      "9493\n",
      "9494\n",
      "9495\n",
      "9496\n",
      "9497\n",
      "9498\n",
      "9499\n",
      "9500\n",
      "9501\n",
      "9502\n",
      "9503\n",
      "9504\n",
      "9505\n",
      "9506\n",
      "9507\n",
      "9508\n",
      "9509\n",
      "9510\n",
      "9511\n",
      "9512\n",
      "9513\n",
      "9514\n",
      "9515\n",
      "9516\n",
      "9517\n",
      "9518\n",
      "9519\n",
      "9520\n",
      "9521\n",
      "9522\n",
      "9523\n",
      "9524\n",
      "9525\n",
      "9526\n",
      "9527\n",
      "9528\n",
      "9529\n",
      "9530\n",
      "9531\n",
      "9532\n",
      "9533\n",
      "9534\n",
      "9535\n",
      "9536\n",
      "9537\n",
      "9538\n",
      "9539\n",
      "9540\n",
      "9541\n",
      "9542\n",
      "9543\n",
      "9544\n",
      "9545\n",
      "9546\n",
      "9547\n",
      "9548\n",
      "9549\n",
      "9550\n",
      "9551\n",
      "9552\n",
      "9553\n",
      "9554\n",
      "9555\n",
      "9556\n",
      "9557\n",
      "9558\n",
      "9559\n",
      "9560\n",
      "9561\n",
      "9562\n",
      "9563\n",
      "9564\n",
      "9565\n",
      "9566\n",
      "9567\n",
      "9568\n",
      "9569\n",
      "9570\n",
      "9571\n",
      "9572\n",
      "9573\n",
      "9574\n",
      "9575\n",
      "9576\n",
      "9577\n",
      "9578\n",
      "9579\n",
      "9580\n",
      "9581\n",
      "9582\n",
      "9583\n",
      "9584\n",
      "9585\n",
      "9586\n",
      "9587\n",
      "9588\n",
      "9589\n",
      "9590\n",
      "9591\n",
      "9592\n",
      "9593\n",
      "9594\n",
      "9595\n",
      "9596\n",
      "9597\n",
      "9598\n",
      "9599\n",
      "9600\n",
      "9601\n",
      "9602\n",
      "9603\n",
      "9604\n",
      "9605\n",
      "9606\n",
      "9607\n",
      "9608\n",
      "9609\n",
      "9610\n",
      "9611\n",
      "9612\n",
      "9613\n",
      "9614\n",
      "9615\n",
      "9616\n",
      "9617\n",
      "9618\n",
      "9619\n",
      "9620\n",
      "9621\n",
      "9622\n",
      "9623\n",
      "9624\n",
      "9625\n",
      "9626\n",
      "9627\n",
      "9628\n",
      "9629\n",
      "9630\n",
      "9631\n",
      "9632\n",
      "9633\n",
      "9634\n",
      "9635\n",
      "9636\n",
      "9637\n",
      "9638\n",
      "9639\n",
      "9640\n",
      "9641\n",
      "9642\n",
      "9643\n",
      "9644\n",
      "9645\n",
      "9646\n",
      "9647\n",
      "9648\n",
      "9649\n",
      "9650\n",
      "9651\n",
      "9652\n",
      "9653\n",
      "9654\n",
      "9655\n",
      "9656\n",
      "9657\n",
      "9658\n",
      "9659\n",
      "9660\n",
      "9661\n",
      "9662\n",
      "9663\n",
      "9664\n",
      "9665\n",
      "9666\n",
      "9667\n",
      "9668\n",
      "9669\n",
      "9670\n",
      "9671\n",
      "9672\n",
      "9673\n",
      "9674\n",
      "9675\n",
      "9676\n",
      "9677\n",
      "9678\n",
      "9679\n",
      "9680\n",
      "9681\n",
      "9682\n",
      "9683\n",
      "9684\n",
      "9685\n",
      "9686\n",
      "9687\n",
      "9688\n",
      "9689\n",
      "9690\n",
      "9691\n",
      "9692\n",
      "9693\n",
      "9694\n",
      "9695\n",
      "9696\n",
      "9697\n",
      "9698\n",
      "9699\n",
      "9700\n",
      "9701\n",
      "9702\n",
      "9703\n",
      "9704\n",
      "9705\n",
      "9706\n",
      "9707\n",
      "9708\n",
      "9709\n",
      "9710\n",
      "9711\n",
      "9712\n",
      "9713\n",
      "9714\n",
      "9715\n",
      "9716\n",
      "9717\n",
      "9718\n",
      "9719\n",
      "9720\n",
      "9721\n",
      "9722\n",
      "9723\n",
      "9724\n",
      "9725\n",
      "9726\n",
      "9727\n",
      "9728\n",
      "9729\n",
      "9730\n",
      "9731\n",
      "9732\n",
      "9733\n",
      "9734\n",
      "9735\n",
      "9736\n",
      "9737\n",
      "9738\n",
      "9739\n",
      "9740\n",
      "9741\n",
      "9742\n",
      "9743\n",
      "9744\n",
      "9745\n",
      "9746\n",
      "9747\n",
      "9748\n",
      "9749\n",
      "9750\n",
      "9751\n",
      "9752\n",
      "9753\n",
      "9754\n",
      "9755\n",
      "9756\n",
      "9757\n",
      "9758\n",
      "9759\n",
      "9760\n",
      "9761\n",
      "9762\n",
      "9763\n",
      "9764\n",
      "9765\n",
      "9766\n",
      "9767\n",
      "9768\n",
      "9769\n",
      "9770\n",
      "9771\n",
      "9772\n",
      "9773\n",
      "9774\n",
      "9775\n",
      "9776\n",
      "9777\n",
      "9778\n",
      "9779\n",
      "9780\n",
      "9781\n",
      "9782\n",
      "9783\n",
      "9784\n",
      "9785\n",
      "9786\n",
      "9787\n",
      "9788\n",
      "9789\n",
      "9790\n",
      "9791\n",
      "9792\n",
      "9793\n",
      "9794\n",
      "9795\n",
      "9796\n",
      "9797\n",
      "9798\n",
      "9799\n",
      "9800\n",
      "9801\n",
      "9802\n",
      "9803\n",
      "9804\n",
      "9805\n",
      "9806\n",
      "9807\n",
      "9808\n",
      "9809\n",
      "9810\n",
      "9811\n",
      "9812\n",
      "9813\n",
      "9814\n",
      "9815\n",
      "9816\n",
      "9817\n",
      "9818\n",
      "9819\n",
      "9820\n",
      "9821\n",
      "9822\n",
      "9823\n",
      "9824\n",
      "9825\n",
      "9826\n",
      "9827\n",
      "9828\n",
      "9829\n",
      "9830\n",
      "9831\n",
      "9832\n",
      "9833\n",
      "9834\n",
      "9835\n",
      "9836\n",
      "9837\n",
      "9838\n",
      "9839\n",
      "9840\n",
      "9841\n",
      "9842\n",
      "9843\n",
      "9844\n",
      "9845\n",
      "9846\n",
      "9847\n",
      "9848\n",
      "9849\n",
      "9850\n",
      "9851\n",
      "9852\n",
      "9853\n",
      "9854\n",
      "9855\n",
      "9856\n",
      "9857\n",
      "9858\n",
      "9859\n",
      "9860\n",
      "9861\n",
      "9862\n",
      "9863\n",
      "9864\n",
      "9865\n",
      "9866\n",
      "9867\n",
      "9868\n",
      "9869\n",
      "9870\n",
      "9871\n",
      "9872\n",
      "9873\n",
      "9874\n",
      "9875\n",
      "9876\n",
      "9877\n",
      "9878\n",
      "9879\n",
      "9880\n",
      "9881\n",
      "9882\n",
      "9883\n",
      "9884\n",
      "9885\n",
      "9886\n",
      "9887\n",
      "9888\n",
      "9889\n",
      "9890\n",
      "9891\n",
      "9892\n",
      "9893\n",
      "9894\n",
      "9895\n",
      "9896\n",
      "9897\n",
      "9898\n",
      "9899\n",
      "9900\n",
      "9901\n",
      "9902\n",
      "9903\n",
      "9904\n",
      "9905\n",
      "9906\n",
      "9907\n",
      "9908\n",
      "9909\n",
      "9910\n",
      "9911\n",
      "9912\n",
      "9913\n",
      "9914\n",
      "9915\n",
      "9916\n",
      "9917\n",
      "9918\n",
      "9919\n",
      "9920\n",
      "9921\n",
      "9922\n",
      "9923\n",
      "9924\n",
      "9925\n",
      "9926\n",
      "9927\n",
      "9928\n",
      "9929\n",
      "9930\n",
      "9931\n",
      "9932\n",
      "9933\n",
      "9934\n",
      "9935\n",
      "9936\n",
      "9937\n",
      "9938\n",
      "9939\n",
      "9940\n",
      "9941\n",
      "9942\n",
      "9943\n",
      "9944\n",
      "9945\n",
      "9946\n",
      "9947\n",
      "9948\n",
      "9949\n",
      "9950\n",
      "9951\n",
      "9952\n",
      "9953\n",
      "9954\n",
      "9955\n",
      "9956\n",
      "9957\n",
      "9958\n",
      "9959\n",
      "9960\n",
      "9961\n",
      "9962\n",
      "9963\n",
      "9964\n",
      "9965\n",
      "9966\n",
      "9967\n",
      "9968\n",
      "9969\n",
      "9970\n",
      "9971\n",
      "9972\n",
      "9973\n",
      "9974\n",
      "9975\n",
      "9976\n",
      "9977\n",
      "9978\n",
      "9979\n",
      "9980\n",
      "9981\n",
      "9982\n",
      "9983\n",
      "9984\n",
      "9985\n",
      "9986\n",
      "9987\n",
      "9988\n",
      "9989\n",
      "9990\n",
      "9991\n",
      "9992\n",
      "9993\n",
      "9994\n",
      "9995\n",
      "9996\n",
      "9997\n",
      "9998\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = \"I saw a cat jumping onto the table, \"\n",
    "\n",
    "\n",
    "input_idx = util.encode(seed,stoi)\n",
    "\n",
    "input_idx = torch.tensor(input_idx,dtype=torch.long)\n",
    "input_idx = torch.unsqueeze(input_idx, 0).to(device)\n",
    "\n",
    "\n",
    "m.eval()\n",
    "with torch.no_grad():\n",
    "    out = m.generate(10000,input_idx,'hi')\n",
    "    out = util.decode(out,itos)\n",
    "    \n",
    "\n",
    "with open('output3000_2.txt', 'w') as file:\n",
    "# Write the string to the file\n",
    "    file.write(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "I saw a cat jumping onto the table, dish?\n",
      "\n",
      "Resol:\n",
      "Resolve red. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the ple.\n",
      "\n",
      "Ales toplve.\n",
      "Fito Caitit, rs Cizen:\n",
      "\n",
      "You plve. plve plve plve k.\n",
      "Firc  pe plve plve ou the pl plve to plver to die than to famish?\n",
      "\n",
      "Al:\n",
      "Alol:\n",
      "Alved. resolved.\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief eneo theo ple.\n",
      "\n",
      "Ale. topl:\n",
      "Alve. e e. e e ed. plve y tolve t, theoplveoplveoperereoperere rdie to than:\n",
      "\n",
      "Al:\n",
      "Firstoplve to to to to toplve die thaie th?\n",
      "\n",
      "Al:\n",
      "Red. rstooooooooooooooooooooooo\n",
      "\n",
      "Fit Citizen:\n",
      "Firen:\n",
      "Yooooou airchire aiu amy are are ale esoles e red.\n",
      "\n",
      "Fis Caies tius ius Marchienenenemy toll:\n",
      "Fius plve.\n",
      "Fit, plve.\n",
      "Firs y rst, o eno plve peno plve the.\n",
      "\n",
      "Fizeno plvenou plvers to plve\n",
      "\n",
      "Fitow to plverst plven:\n",
      "Fitocplve ple tocplve toche ple pe toce toche die to tohane to famish?\n",
      "\n",
      "Al:\n",
      "Resoolved. red.\n",
      "\n",
      "First Citizen:\n",
      "First, you k.\n",
      "Fircircircircircircircirchirchirchene ple tople ple ple ple dize to to to thaien to f f f f famish?\n",
      "\n",
      "Al:\n",
      "Resolved. red.\n",
      "\n",
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "m.eval()\n",
    "with torch.no_grad():\n",
    "    out = m.generate(1000,input_idx,'high_prob')\n",
    "    print(util.decode(out,itos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
